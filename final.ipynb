{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Visualization and Preprocessing"
      ],
      "metadata": {
        "id": "rTghdCJsBRC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "cifar100_trainset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "cifar100_classes = cifar100_trainset.classes\n",
        "\n",
        "# Load SVHN dataset\n",
        "svhn_trainset = torchvision.datasets.SVHN(\n",
        "    root='./data', split='train', download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Function to display images and labels\n",
        "def imshow(img, labels, classes, title):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Display CIFAR-100 samples\n",
        "data_loader_cifar100 = torch.utils.data.DataLoader(cifar100_trainset, batch_size=4, shuffle=True)\n",
        "dataiter_cifar100 = iter(data_loader_cifar100)\n",
        "images_cifar100, labels_cifar100 = next(dataiter_cifar100)\n",
        "\n",
        "# Get label names for CIFAR-100\n",
        "cifar100_label_names = [cifar100_classes[label] for label in labels_cifar100]\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images_cifar100), labels_cifar100, cifar100_classes, \\\n",
        "       f\"CIFAR-100: {', '.join(cifar100_label_names)}\")\n",
        "\n",
        "# Display SVHN samples\n",
        "data_loader_svhn = torch.utils.data.DataLoader(svhn_trainset, batch_size=4, shuffle=True)\n",
        "dataiter_svhn = iter(data_loader_svhn)\n",
        "images_svhn, labels_svhn = next(dataiter_svhn)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images_svhn), labels_svhn, [str(i) for i in range(10)], \\\n",
        "       f\"SVHN: {', '.join(labels_svhn.numpy().astype(str))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "Qept5-zWA2Uz",
        "outputId": "4229ace9-1d5d-4b2d-8e9f-7a0975de9cb4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:03<00:00, 43.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182M/182M [00:08<00:00, 22.2MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAEMCAYAAAAWMSOjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuXklEQVR4nO3dd5xU1d0/8M/0mZ2dsr2wLL2DqCCIiETFIBLFiC1RQWMsETRKEltiSCxBxUSNQYyJP81jSx4TlRhjjBRFDSKCWEDpZSnbd7ZOn/P7g+w8Lud7cFfaTvJ5v168Er979s65955775ydPZ+1KKUUiIiIiIiIMpj1aHeAiIiIiIjoYHFiQ0REREREGY8TGyIiIiIiynic2BARERERUcbjxIaIiIiIiDIeJzZERERERJTxOLEhIiIiIqKMx4kNERERERFlPE5siIiIiIgo43FiQ0R0mD311FOwWCzYvn37YXuN7du3w2Kx4IEHHjhsr0Hd1+WXX47s7Oyj3Y2M0n7NPPXUU4d0uxaLBbNnzz6k2ySizuHEhiiDbNmyBddccw369u0Lt9sNv9+P8ePH4+GHH0Y4HE636927N77xjW90+F6LxSL+Ky4u7tAuFArB7XbDYrHgs88+E/tx+eWXd9iGy+XCwIED8dOf/hSRSKRT+/L+++/juuuuw6hRo+BwOGCxWA7Y/oknnsCQIUPgdrsxYMAAPPLII2K73bt348ILL0QwGITf78e0adOwdevWTvVJsmfPHvzsZz/D2rVrv/I2iIiI6PCzH+0OEFHnvPrqq7jgggvgcrkwY8YMDB8+HLFYDO+88w5+9KMfYd26dXj88ccPuI0zzjgDM2bM6FDzeDwd/vuFF15IT3ieffZZ3H333eK2XC4Xfv/73wMAGhsbsWjRItx1113YsmULnn322S/dn7///e/4/e9/j2OOOQZ9+/bFxo0bjW1/+9vf4tprr8X06dMxZ84cvP3227jhhhvQ1taGW265Jd2upaUFp556KhobG3H77bfD4XDgwQcfxMSJE7F27Vrk5eV9ab/2t2fPHvz85z9H7969ceyxx3b5+4mIiOjI4MSGKANs27YNF198MXr16oWlS5eipKQk/bVZs2Zh8+bNePXVV790OwMHDsSll156wDbPPPMMzjrrLPTq1QvPPfeccWJjt9s7bOu6667DSSedhOeffx6/+tWvUFRUdMDX+d73vodbbrkFHo8Hs2fPNk5swuEwfvzjH2Pq1Kn485//DAC46qqrkEqlcNddd+Hqq69GTk4OAODRRx/Fpk2b8P777+OEE04AAEyZMgXDhw/HL3/5S/ziF784YJ+I6D9LW1sbsrKyDmobra2t8Hq9h6hHRHQ48VfRiDLA/fffj5aWFjzxxBMdJjXt+vfvj+9///sH/To7d+7E22+/jYsvvhgXX3wxtm3bhn/961+d+l6LxYKTTz4ZSqlO/epXUVGR9mmRZNmyZairq8N1113XoT5r1iy0trZ2mND9+c9/xgknnJCe1ADA4MGDcfrpp+N///d/O3z/zp078fnnnx/wtd988830tq644or0r9598XfyV65ciTPPPBOBQABZWVmYOHEi3n333S/dLwB47bXXMGHCBHi9Xvh8PkydOhXr1q3r0KZ97cTWrVsxefJkeL1elJaW4s4774RSStzu448/jn79+sHlcuGEE07AqlWrtDZLly5Nv3YwGMS0adO0Xz382c9+BovFgs2bN+Pyyy9HMBhEIBDAFVdcgba2Nm2bzzzzDEaNGgWPx4Pc3FxcfPHFqKio6NSx2N8X1ww9+OCD6NWrFzweDyZOnIhPP/30K+1Pc3MzbrzxRvTu3RsulwuFhYU444wzsGbNmnSbTZs2Yfr06SguLobb7UZZWRkuvvhiNDY2duiXtC7DYrHgZz/7mXb8Nm7ciEsvvRSBQAAFBQW44447oJRCRUUFpk2bBr/fj+LiYvzyl7/8SsfqizozTlpbW/GDH/wAPXv2hMvlwqBBg/DAAw90aDdx4kSMHDlSfI1BgwZh8uTJXerXxx9/DIvFgr/+9a/p2urVq2GxWHD88cd3aDtlyhSMHTs2/d+LFi3C1KlTUVpaCpfLhX79+uGuu+5CMpns8H1f+9rXMHz4cKxevRqnnHIKsrKycPvttwPY9yu2l19+OQKBAILBIGbOnIlQKKT1s/1627JlC8466yz4fD5ccsklnT5uX/Tss89i0KBBcLvdGDVqFJYvX6612b17N77zne+gqKgILpcLw4YNw//7f/+vcweViDSc2BBlgFdeeQV9+/bFSSeddFDbiUQiqK2t7fAvGo2mv/7888/D6/XiG9/4BsaMGYN+/fp16tfK2rUvjm//BOVQ+PDDDwEAo0eP7lAfNWoUrFZr+uupVAoff/yx1g4AxowZgy1btqC5uTldmzFjBoYMGXLA1x4yZAjuvPNOAMDVV1+Np59+Gk8//TROOeUUAPveTJ9yyiloamrC3Llz8Ytf/AKhUAinnXYa3n///QNu++mnn8bUqVORnZ2N++67D3fccQfWr1+Pk08+WQsZSCaTOPPMM1FUVIT7778fo0aNwty5czF37lxtu8899xzmz5+Pa665BnfffTe2b9+O8847D/F4PN1m8eLFmDx5Mqqrq/Gzn/0Mc+bMwb/+9S+MHz9eDDi48MIL0dzcjHnz5uHCCy/EU089hZ///Ocd2txzzz2YMWMGBgwYgF/96le48cYbsWTJEpxyyiniG8jO+p//+R/8+te/xqxZs3Dbbbfh008/xWmnnYaqqqou78+1116LhQsXYvr06Xj00Ufxwx/+EB6PJz0BisVimDx5Mt577z1cf/31WLBgAa6++mps3br1oPbhoosuQiqVwr333ouxY8fi7rvvxkMPPYQzzjgDPXr0wH333Yf+/fvjhz/8ofjmt7M6M06UUjjnnHPw4IMP4swzz8SvfvUrDBo0CD/60Y8wZ86cdLvLLrsMH3/8sTaJXLVqVXqi1hXDhw9HMBjssH9vv/02rFYrPvroIzQ1NQHYdx3/61//Sl9jwL7wjezsbMyZMwcPP/wwRo0ahZ/+9Ke49dZbtdepq6vDlClTcOyxx+Khhx7CqaeeCqUUpk2bhqeffhqXXnop7r77buzatQszZ84U+5pIJDB58mQUFhbigQcewPTp0zt93Nq99dZbuPHGG3HppZfizjvvRF1dHc4888wOx7OqqgonnngiFi9ejNmzZ+Phhx9G//79ceWVV+Khhx7q0vElon9TRNStNTY2KgBq2rRpnf6eXr16qalTp3aoARD/Pfnkk+k2I0aMUJdcckn6v2+//XaVn5+v4vF4h23NnDlTeb1eVVNTo2pqatTmzZvVAw88oCwWixo+fLhKpVJd2sdZs2Yp0+1o1qxZymaziV8rKChQF198sVJKqZqaGgVA3XnnnVq7BQsWKADq888/T9cmTpxofM0vWrVqlXaclFIqlUqpAQMGqMmTJ3fY37a2NtWnTx91xhlnpGtPPvmkAqC2bdumlFKqublZBYNBddVVV3XYZmVlpQoEAh3qM2fOVADU9ddf3+G1p06dqpxOp6qpqVFKKbVt2zYFQOXl5an6+vp020WLFikA6pVXXknXjj32WFVYWKjq6urStY8++khZrVY1Y8aMdG3u3LkKgPrOd77ToZ/f/OY3VV5eXvq/t2/frmw2m7rnnns6tPvkk0+U3W7X6p3Rvj8ej0ft2rUrXV+5cqUCoG666aYu708gEFCzZs0yvuaHH36oAKgXXnjhS/u1/3hQat81Nnfu3PR/tx+/q6++Ol1LJBKqrKxMWSwWde+996brDQ0NyuPxqJkzZxpf+0A6O05efvllBUDdfffdHb7//PPPVxaLRW3evFkppVQoFFJut1vdcsstHdrdcMMNyuv1qpaWli73cerUqWrMmDHp/z7vvPPUeeedp2w2m3rttdeUUkqtWbNGAVCLFi1Kt2tra9O2dc0116isrCwViUTStfZr+rHHHuvQtn2f77///nQtkUioCRMmaOey/Tjeeuut4ja+7Lgp9X/32g8++CBd27Fjh3K73eqb3/xmunbllVeqkpISVVtb22GbF198sQoEAuJ+E9GB8RMbom6u/SeZPp/voLc1bdo0vPHGGx3+tf9Kyccff4xPPvkE3/rWt9Ltv/Wtb6G2thavv/66tq3W1lYUFBSgoKAg/dPm8ePHY9GiRV+acNYV4XAYTqdT/Jrb7U6nwbX/r8vlEtt9sQ2w79fMlOFXSDpj7dq12LRpE7797W+jrq4u/QlYa2srTj/9dCxfvhypVEr83jfeeAOhUCh9fNv/2Ww2jB07FsuWLdO+54vxse1xsrFYDIsXL+7Q7qKLLurwidmECRMAIP3rgXv37sXatWtx+eWXIzc3N93umGOOwRlnnIG///3v2mtfe+21Hf57woQJqKurS4/NF198EalUChdeeGGH/SkuLsaAAQPE/emsc889Fz169Ej/95gxYzB27Nh0P7uyP8FgECtXrsSePXvE1woEAgCA119/XfxVu6/qu9/9bvr/22w2jB49GkopXHnllR36NmjQoINK8AO+fJz8/e9/h81mww033NDh+37wgx9AKYXXXnsNwL5jMW3aNDz//PPp6ySZTOJPf/oTzj333K+05mTChAlYs2YNWltbAQDvvPMOzjrrLBx77LF4++23Aez7FKf911rbffFXVpubm1FbW4sJEyagra1N+3VSl8uFK664okPt73//O+x2O773ve+lazabDddff72xr19s276Nzhy3duPGjcOoUaPS/11eXo5p06bh9ddfRzKZhFIKf/nLX3D22WdDKdXhupk8eTIaGxs7/IokEXUOwwOIujm/3w8AHX6N6qsqKyvDpEmTxK8988wz8Hq96Nu3LzZv3gxg34Sgd+/eePbZZzF16tQO7d1uN1555RUAwK5du3D//fejurq6w5uQlpYWtLS0pP/bZrOhoKCgS332eDyIxWLi1yKRSPr12v/3i79a98V2X2xzKGzatAkAjL/OAuxLi5N+La/9e0877TTx+9rPeTur1Yq+fft2qA0cOBAAtF8dKy8v7/Df7a/f0NAAANixYweAfesk9jdkyBC8/vrr2mLpA23T7/dj06ZNUEphwIAB4v44HA6x3hnSNgcOHJheM9WV/bn//vsxc+ZM9OzZE6NGjcJZZ52FGTNmpI9tnz59MGfOHPzqV7/Cs88+iwkTJuCcc85Jr4/5qvY/foFAAG63G/n5+Vq9rq7uK79OZ8bJjh07UFpaqv2gpP3XMtuPJ7Dv1zX/9Kc/4e2338Ypp5yCxYsXo6qqCpdddtlX6t+ECROQSCSwYsUK9OzZE9XV1ZgwYQLWrVvXYWIzdOjQDpPUdevW4Sc/+QmWLl2anky3a1/71K5Hjx7aD0J27NiBkpIS7e/8SGMG2BeMUlZWpm2js8cNMI/btrY21NTUwGq1IhQK4fHHHzemWVZXV4t1IjLjxIaom/P7/SgtLRUXTB8qSik8//zzaG1txdChQ7WvV1dXo6WlpcMbA5vN1mGSNHnyZAwePBjXXHNNeoHwAw880GEtRq9evbr8RypLSkqQTCZRXV2NwsLCdD0Wi6Gurg6lpaUAgNzcXLhcLuzdu1fbRnutve2h0P5pzPz5840x0KY/mNj+vU8//bT2d4SAfW+sviqbzSbWD+bTqS/bZiqVgsViwWuvvSa27S5/OPLCCy/EhAkT8NJLL+Gf//wn5s+fj/vuuw8vvvgipkyZAgD45S9/icsvvxyLFi3CP//5T9xwww2YN28e3nvvPZSVlRk/jdx/IfsXScfkcJynQ23y5MkoKirCM888g1NOOQXPPPMMiouLjT8c+TKjR4+G2+3G8uXLUV5ejsLCQgwcOBATJkzAo48+img0irfffhvf/OY3098TCoUwceJE+P1+3HnnnejXrx/cbjfWrFmDW265RftU9FD88MLlcsFqPby/0NLe70svvdT4w5FjjjnmsPaB6D8RJzZEGeAb3/gGHn/8caxYsQLjxo075Nt/6623sGvXLtx5553agvqGhgZcffXVePnllw+4YLikpAQ33XQTfv7zn+O9997DiSeeiBkzZhh/paSz2icNH3zwAc4666x0/YMPPkAqlUp/3Wq1YsSIEfjggw+0baxcuRJ9+/b9Sr/OZ3oj269fPwD7Jp5dfaPX/r2FhYWd+t5UKoWtW7emf/oOIB2P3bt37y69dq9evQAAGzZs0L72+eefIz8/v8u/ZtSvXz8opdCnT58OfTwU2j/d+qKNGzem97ur+1NSUoLrrrsO1113Haqrq3H88cfjnnvuSU9sAGDEiBEYMWIEfvKTn6RDCB577DHcfffd6U+r9g8T2P8n9kdDZ8ZJr169sHjxYjQ3N3e4Htp/pav9eAL7Jl/f/va38dRTT+G+++7Dyy+/jKuuuso4KfsyTqcTY8aMwdtvv43y8vL0r0lOmDAB0WgUzz77LKqqqjoEB7z55puoq6vDiy++2KG+bdu2Tr9ur169sGTJEu2HM9KYOdA2OnvcAPO4zcrKSn9q7fP5kEwmv/JEkYh0XGNDlAFuvvlmeL1efPe73+2QBtVuy5YtePjhh7/y9tt/De1HP/oRzj///A7/rrrqKgwYMKBT6WjXX389srKycO+99wIA+vbti0mTJqX/jR8/vst9O+2005Cbm4uFCxd2qC9cuBBZWVkdfkXu/PPPx6pVqzpMbjZs2IClS5figgsu6PD9nYl7BpB+U7z/G9lRo0ahX79+eOCBBzr8ul27mpoa4zYnT54Mv9+PX/ziFx3Syg70vb/5zW/S/18phd/85jdwOBw4/fTTv3QfvqikpATHHnss/vCHP3TYp08//RT//Oc/O0weO+u8886DzWbDz3/+c+0TB6XUQf161csvv4zdu3en//v999/HypUr0xORzu5PMpnUfm2psLAQpaWl6V9fbGpqQiKR6NBmxIgRsFqt6TZ+vx/5+flaetmjjz76lffxUPqycXLWWWchmUx2aAcADz74ICwWS4cJHrAvHa2hoQHXXHMNWlpaupyGtr8JEyZg5cqVWLZsWXpik5+fjyFDhuC+++5Lt2nXPon64riKxWJdOt5nnXUWEolEh3tIMpnEI4880qVtdOW4rVixosMamYqKCixatAhf//rXYbPZYLPZMH36dPzlL38RP40/0P2DiMz4iQ1RBujXrx+ee+45XHTRRRgyZAhmzJiB4cOHIxaL4V//+hdeeOEFXH755V9p29FoFH/5y19wxhlnpBfZ7++cc87Bww8/rP062P7y8vJwxRVX4NFHH8Vnn312wDjlHTt24OmnnwaA9ESk/Y+B9urVK/17/B6PB3fddRdmzZqFCy64AJMnT8bbb7+NZ555Bvfcc0+H38W/7rrr8Lvf/Q5Tp07FD3/4QzgcjvQfC/3BD37Q4fVnzJiBt95660t/9adfv34IBoN47LHH4PP54PV6MXbsWPTp0we///3vMWXKFAwbNgxXXHEFevTogd27d2PZsmXw+/3pNUj78/v9WLhwIS677DIcf/zxuPjii1FQUICdO3fi1Vdfxfjx4zu8gXK73fjHP/6BmTNnYuzYsXjttdfw6quv4vbbb+/ymiVg36/PTZkyBePGjcOVV16JcDiMRx55BIFAoMPfYemsfv364e6778Ztt92G7du349xzz4XP58O2bdvw0ksv4eqrr8YPf/hDAPt+An/qqadi7ty5nXqt/v374+STT8b3vvc9RKNRPPTQQ8jLy8PNN9/cpf1pbm5GWVkZzj//fIwcORLZ2dlYvHgxVq1alf77MUuXLsXs2bNxwQUXYODAgUgkEnj66afTb0Lbffe738W9996L7373uxg9ejSWL19u/AOzB+trX/tap8Yp0LlxcvbZZ+PUU0/Fj3/8Y2zfvh0jR47EP//5TyxatAg33nhj+tPEdscddxyGDx+OF154AUOGDNH+5gyw72+//OEPf8C2bdu+9BPECRMm4J577kFFRUWHCcwpp5yC3/72t+jdu3eH9S0nnXQScnJyMHPmTNxwww2wWCx4+umnu/Qre2effTbGjx+PW2+9Fdu3b8fQoUPx4osvahPdL9tGV47b8OHDMXnyZNxwww1wuVzpidgXfzX33nvvxbJlyzB27FhcddVVGDp0KOrr67FmzRosXrwY9fX1ne4fEf3bEc1gI6KDsnHjRnXVVVep3r17K6fTqXw+nxo/frx65JFHOsSemuKepajbv/zlLwqAeuKJJ4yv++abbyoA6uGHH1ZK/V/cs2TLli3KZrN9aWztsmXLjBHUEydO1No//vjjatCgQcrpdKp+/fqpBx98UIyVrqioUOeff77y+/0qOztbfeMb31CbNm3S2nU27lmpfZHJQ4cOVXa7XYuH/fDDD9V5552n8vLylMvlUr169VIXXnihWrJkSbrN/nHPXzwGkydPVoFAQLndbtWvXz91+eWXd4iJbT/WW7ZsUV//+tdVVlaWKioqUnPnzlXJZDLdrj2GeP78+Vr/sV8MsVJKLV68WI0fP155PB7l9/vV2WefrdavX9+hTXtccXtU8Jftz1/+8hd18sknK6/Xq7xerxo8eLCaNWuW2rBhQ7rNK6+8Ikby7u+L+/PLX/5S9ezZU7lcLjVhwgT10Ucfae2/bH+i0aj60Y9+pEaOHKl8Pp/yer1q5MiR6tFHH0232bp1q/rOd76j+vXrp9xut8rNzVWnnnqqWrx4cYfXamtrU1deeaUKBALK5/OpCy+8UFVXVxvjnvc/fqbrZ+LEiWrYsGEdaqNGjVLFxcUHPFZf3OaXjROl9sWN33TTTaq0tFQ5HA41YMAANX/+fGNM+/33368AqF/84hfi16dPn648Ho9qaGj40n42NTUpm82mfD6fSiQS6fozzzyjAKjLLrtM+553331XnXjiicrj8ajS0lJ18803q9dff10BUMuWLUu3k45fu7q6OnXZZZcpv9+vAoGAuuyyy9Lx3vvHPZvubZ09bu332meeeUYNGDBAuVwuddxxx3Xoa7uqqio1a9Ys1bNnT+VwOFRxcbE6/fTT1eOPP36Ao0hEJhalutFKRSIi6uDyyy/Hn//8Z/HX3TLRzTffjOeffx6bN28Wo7nbbd++HX369MH8+fPTn/b8t2lubkZubi4eeughzJo166j14+GHH8ZNN92E7du3awlvAFBUVIQZM2Zg/vz5R6F3RET/h2tsiIjoiFm2bBnuuOOOA05qaJ/ly5ejR48euOqqq45aH5RSeOKJJzBx4kRxUrNu3TqEw2HccsstR6F3REQdcY0NEREdMatWrTraXcgYU6dO1f5+1JHS2tqKv/71r1i2bBk++eQTLFq0SGw3bNgw7W/LEBEdLZzYEBERUQc1NTX49re/jWAwiNtvvx3nnHPO0e4SEdGX4hobIiIiIiLKeFxjQ0REREREGY8TGyIiIiIiyniHbY3NggULMH/+fFRWVmLkyJF45JFHMGbMmC/9vlQqhT179sDn88FisRyu7hERERERUTenlEJzczNKS0thtR74M5nDssbmT3/6E2bMmIHHHnsMY8eOxUMPPYQXXngBGzZsOOBfLQeAXbt2oWfPnoe6S0RERERElKEqKipQVlZ2wDaHZWIzduxYnHDCCfjNb34DYN+nMD179sT111+PW2+99YDf29jYiGAwiJtuuol/54CIiIiI6L9YNBrFgw8+iFAohEAgcMC2h/xX0WKxGFavXo3bbrstXbNarZg0aRJWrFghdjYajab/u7m5GQDgcrk4sSEiIiIiok4tUTnk4QG1tbVIJpMoKirqUC8qKkJlZaXWft68eQgEAul//DU0IiIiIiLqqqOeinbbbbehsbEx/a+iouJod4mIiIiIiDLMIf9VtPz8fNhsNlRVVXWoV1VVobi4WGvPXzkjIiIiIqKDdcg/sXE6nRg1ahSWLFmSrqVSKSxZsgTjxo071C9HRERERER0eP6OzZw5czBz5kyMHj0aY8aMwUMPPYTW1lZcccUVh+PliIiIiIjov9xhmdhcdNFFqKmpwU9/+lNUVlbi2GOPxT/+8Q8tUICIiIiIiOhQOCwTGwCYPXs2Zs+efbg2T0RERERElHbYJjZHymvvbRPr0t8d/fL060NP+uunytSTTuRzf/kL6q9o+husFpXSanar3Nbrcop1f7ZHq2Vn6TUAcNjk/UvEIlot2tYmtm2L6/2ra0vI29V3DwBgEc6Kshy+gEDpiJqy2Kec2KfT2y0JxMT6nj3VWi2VlLehlE2s762s0WrhhHycw+GQVisozBHbjhg5WKzn5el/cMttk/uWjMv98Pl8Ws3v94ttU8I1kUwZxpGSD14qpQ+wSDgstpUuwV27dottm5v06wEAolH9fLe2toptXYbr1W7Xb/lOw3G2WvR6S1gec8mUvI2YcEhDjc1i2x7lg8S65JZbbhHrVqt+HdsM+9eZv4fQLhKRz8mh+PvW0jmJxeTjLO2Laf/i8bhYl/ZbOm4AjME+UnvpejC1TSblay0Slo9zQrj3OA1j3OFwaDXpGAOA5TDe97viZz/7Wafb3nnPnWK9v1ffxyF+eWxk2eVxm2XXx4bdJp9Xu7ANu37oAQAuw/sKu1V/PZvhunTYhNczvKewOeT9dtn1fXE65L7ZDNeEw6Y/D0zvm2w2fRtWQ59NQ1EaozbhuAFAPKLXQ/Vy2yb50YGmqH6MmmPyGPikQd7vFdX69RpNyW3n/vQOuSMHoXtc1URERERERAeBExsiIiIiIsp4nNgQEREREVHG48SGiIiIiIgyHic2RERERESU8TI+FU2MGzLUDz6/puuk10xaDXFdUpKbIUnCaqhLSR5ZHjnZJi+oJ1Hl5eg1AMjOcot1xPQUqMaGOrFpQ7We1rWvfYNWsxsSSbx5hVrNY0hAaYrIyTtKCgk5BOlGR1pOdrZYLxiSq9ViMTnZy+mQz+sG11attru6SmybzNKPfywiR64018ljwyEkjzUm5NtTY0hO1Uom9W0UFBaIbXNz9GNkdcjXpT/oFesup37s2hJyKlpSSIzq1VNOwIsZEmj27N6j1eJS7BiApCES0OfN0moNDY1i29ZWPaEq1CynFba0yQlcdoeekKggX689xKrMlGgm1aVx0VWm5LGu6EoKm9MpJ35JyWOm7Zr63JVtSGlkxvaGbaSESMak4f7QVKunMQJAS7N+zbvd8nMt26cnIYbD8riNxuRxW1TWS389j3wfsJrO66FIORWolPxstCb0Z9gx2fJzLd8l3x+cFv1cOZ3yfliFtDSbIW3N4TBsQygbn8Qp/ZpwZ8sxbHa3adzqdVPfUlb5vmF1CsdIHoqwCjtoTMU1vOdJKb3ucMnP/niL3jd3RH4mBQzjMyKltgXlZ3FFVL5+4klhfB3BBEJ+YkNERERERBmPExsiIiIiIsp4nNgQEREREVHG48SGiIiIiIgyHic2RERERESU8TI/Fe0IU4ciPSspJ3ZIGTZ+l54qBAD5gRyxXiKkQAUDPrFtKhHTak2herFt9bZtYr2xWU9UikbkBBoVlxM0LEn9mCYT8jaSUT1Nx+WSj4UtLp+rpJgol3mpaOGmJsNX9J9XhNvkZJS8XDk1rF+vUq1WXl4itvX79bSgaEw+f1DyGMjLz9Nq1TVyWpc/W089AgCPR79WYjF9jANATY2e8BZPRMW2vkY5DSkc1o9pS3OL2Nbh1NN77HY50cefHRTrBXn5Wi3bkNQUCoXEekK493g8csJOW0RPtvEH5PuRNyDvS2OTPg5a2/S0ta6y2+VHl5QEJqWAHYh0j7caEou6oiupaF15zpi225X97krfAEBJ2zakHqmkfs3vWL9GbLtzy+di3ePR0/yKiorEtlnJoFaLCalqANDcIt+nfH49HdRheBZbDOlzxrS0g2U4rQ0xYcwY+ubzyeeqrUnfeDhiSDQT0sTshgDCREJ+PfkQya8X8On3mKAhsdIunyo0VYe0WjwsH1CLcM8GgLiQMJqMG8610retDIm2Frd8T3PlBLWaO1d+z+P26ePc4Zb3r6lafla1VAupiW79+gMAm9uQvCi8n7IcwfdY/MSGiIiIiIgyHic2RERERESU8TixISIiIiKijMeJDRERERERZbyMDw8wzcwSKf0rKciL9i2QV7w5hYV3VsNiPNPiS7tVrxfk54pte5YU621z9EXVAJCMyIuiQ3V1Wq1i0y6xbUODHhQQi3ZtYa/NoS+w8xgWWcLpFsspYUGzKYAgGtH753IaFn075XMVkhYLHq6FnodR1e7dYr2kRF/kX5CrL4YFgMbGarHuEhalu7PlEIpETAh0sMlXZjgihwfU1+j9sFrkxYYFBUGxbhNes6ZG7xsA5OXqYzHbVyi2jcQMYR/C63mz5LEfjepjtKlJXtBc1WYIzkjo47alVV4A6nHL/fAI/cvKkq9Li02/tiPCwlkA8GbL9zSrtUbfrmGReVeY7rdS3bTwv6sL5o+kQ9E3c+CBvm3jqxlCDKTlyKaXiwjBJTvXrxPbblu/VqznFeshJ1lW+V6S7dRrBYGg2LYgRw5PSQmLvi2GcBGL3fBcE47doRj7pqCblDBmEoaF6tk58rPR4dMPnum9RpZXfz2b23BdpuS6TTge0n0VAFxOl75dt9zWE5ADZsIR/XmQUvJ5tXvlBfNWYfSnEvIzIp7Q75dWw9XmtBsW6Ct92zaLHAYE4T2Pxyufa/gMV32bXo8lDAv/k50PKDkUuVudxU9siIiIiIgo43FiQ0REREREGY8TGyIiIiIiynic2BARERERUcbjxIaIiIiIiDJexqeiKUPCRJZD37UsjxCXAiA7S0//AYAst55S4RC2CwBJQzqElJKU7ZK30dYU0mofb94otm0ONYn1hJDOYUxss+v9cDjlY2Hahk1IibMLSWkAoISkGQAQgs4AIQEFABIpPQnHZUircdnkZCiHMJ2PH8HEjkMlL19OzGtsDmm1bL98LPoOKBfr1bV6ul4kJqd4SSk2EUMEikVICQQAmxSppOQ0nlhUHvsulz5migrldJxYTB9HSSWnLPn9clpNQb6eNBcR0s8AoLpaT30LhWrFtk6HPPaLevbQalJKIAC0tsppcHa7kHRmSD2ypPR9qa2sFNuu2fWeWLdKiVEW+f6A/v3lOn0lFnPWWacpwyZSUjKXRb6/h6N6glM0ZBifEXkb0Tr9mm8L6KmeAJDw6/fFvfXydeILykmIqZj+XLMI9xcAyHbKz3NlldKoDsHPko3nRBc3pJyqpPxeyCHsi9shp2q5vfoYcPvk/Yu2yedVSkUzBcclhUTNlCHwK9wkj6+Y0A+3T96I0y0fI4tV30bSMG5TMf0emjSdQIv8/LFJZzYlp1NabNl6zfR6huOshOtYmZL4kt3zjRM/sSEiIiIioozHiQ0REREREWU8TmyIiIiIiCjjcWJDREREREQZL+PDA5yGhW3BLL1emh8U2zqExc8AYLPph8fplBeUtbS0yB2M6Qsn123YKjZtbdS3YTespHMZFvlnufXFusqw8D+Vkhe8SayGY2QVwhTsrq4FEGT79QXeWX6v2La0pFSrhVvlBZKffL5Bfj233o+GNj10AYB5JWM3cPyY0WK9Ytd2rebzyQvgFeT99uXqxz8sLLgHgGRCH0fBYI7YNidHrsei+rYjbfICULfhGpSEw/r1BwDxqN5nl0e+HaYS8jbcPv1ay/LI49btLNJqxx87TGxbU10j1mvr9LABr0c+r17h/gcAbpfe54Bw/QFAU5MeFtGjWD5/5WXyIuzWNv28NrW0iW3pKzKt3+3Cul5lWrBt2oZwL7ca3k54hWsiL08eL6pWDtRIJfVx1LqnQW5bpN/TPG6f2NZhk+8ltiz9unIawgPMz4iDD28QGc6JFGBkeuY63HKfIwl94youv08Qw4AMbykshoGkhJCZlCGxItWqjwG3y9A2IT+rok362HDaDefJI29DOYTwAMOzEULd7ZXv2XaXHPBjs+j3S4vhGFmFUAGL1TBgDAE/SSFJKWVIV0oZQrOOtu77ro2IiIiIiKiTOLEhIiIiIqKMx4kNERERERFlPE5siIiIiIgo43FiQ0REREREGS/jU9HcSk7E2rVjr1YLeoaKbQsL9MQiALAJSWDZvmyxrc+QLFRTXa3VvAG5bSQW02ouu5ww5hAS2wDA4dDbpwzpF4mEkIhlaOtwyOkxBSX6scvNy5PbFhSI9fLycq1WUt5DbJsT0Lf92cefiW137t4t1iONdVpNOm4AEIsLKSOGpJkjLan0vgGAxab3ryWsJ1z9eyti1e7WE4AcWXIqULRZT/NLGOJxqurqxXo8qo/F8uJeYluPS06Vka7XRFxOfYvGolotCTmFLRwLifW21iatFovr1zAA+IT7hmHIwe2Rf94UDuuv5/XKKWy5eXIKVCqpn2+bRe5zXlBP6bFZ5fMaCcupkH17l2m1WEIec1srxfJ/Pume25V7jKmpMdGs85s2BipF9XNYvUVO+9yzcYteTMpjPMsfFOuxFv3+ZU3J20hF9Gs+UCA/c6OGg+EL6P1weuTUKtPxPHyPCUNCVarz48iUAJkQ3k4l4oZEVKEs3ccBwGI4VxD6LATg/XvjUifk+5HhbROkcFerYZCnUoZ9EZLAXIYk2ISQzmY1JPmmDOl6SeEZZjG8dbcK9/doXD6gKSnVbt8X9D4IyacHqsu6ENN4kPiJDRERERERZTxObIiIiIiIKONxYkNERERERBmPExsiIiIiIsp4nNgQEREREVHGy/hUtFRETwoCgJb6Gq1WXV0rts3LLxHrLpdbq9nscjJUaQ89/QcAFPS0jHBET2QCgLa2sFZLmhIt5GANpIRELItp/iqk8dis8pAoKpH3r3d/Pblq/MkniW0LCgrlbqT0ZI1de+WIpLVrlmu1rZu3iW2h5EQYW1Lfb5ddbiuHasltzeFEhycNZIeUNgQgICRixYS0FAAINTaKdb8zR6vlFuaLbXOF66ehXh7j6z7fIdZdTr3PhUV6HwAgGZePZ262njzWo7ch8dCij/PtWz8X21bulu8bJaV6Qp8zKI8Ch0Pvs8OQxuOyygk7JQXFWi3ULJ+/yio9jREA8gr0c9jcKp+reFivRw0pc8GgnDqV7dPvlw2NcoJat2a6hIXDkTSlVhnuMVYpuSoqJ9UlI2369zsM9zmPnOAZs+gPD2VIw3TF5dSjvdv0e+4bf10ktq3btkerZQflMZ6My+mNLuE52DNfvrYdVv25Xd8q3/9Wbv1ErJ9WUqrVCnLlZNCk8PwCAJvwRDiceZopYRzJew0kDcmElpS+DasheUwOp5T3UApgBYBYWO9HKimPjZTw3DbtoN3w/shuFfonbReAxXBNSGFihrcaYtKZxdhYPs6JlHCMDAfUIrxeKim3TcVM+6f3TxmO0REMOusSfmJDREREREQZjxMbIiIiIiLKeJzYEBERERFRxuPEhoiIiIiIMl6XwwOWL1+O+fPnY/Xq1di7dy9eeuklnHvuuemvK6Uwd+5c/O53v0MoFML48eOxcOFCDBgw4FD2Oy0vT15gXLF1s1ZrrKsT27Y0hcR6wNdDq1kNi+NUQl5F1ae8r1YL1cr9iPj18ICamir59QzrzxLQF6BZDYEALq++uDQQ0BdEA4DHFxTr4bC+qLO2pkFsu21bhVjfvEk/Vy1t8uJZX06uVrP7xFWMsHv0RaQA4Gn1aLXWVnlBs8OubyMWNywCFquAuMLuEKwibTQswrYIKyeThlWW0ajckYZ6fZGyzRUR2zqc+qLatWs3im3XfiQHHuTn64t1o/KaduTlyOd76GD9Wosn5AWZDqveZ4dDDzAAgGFDR4t1d5awMNQqd3rP3q1arbWlVWzr88gL8R02/XxblDzqIhH5+pHGjN8lLzK3CI+HeFzePyUtgAfQ0KDfC5xu+fx1Z6Y1sq0WfXylpAXKAGxh/ZoCgNR6/ZpoW7ZSbBvZoF9XSSnBAID3jIli3Xfm6XrRI5+TuopdYn3XNj1oo3hYH7FtfpkeMBOplsMtYJHvMdGIPm6tefKzCvn6M6KgXO7bicVycJCzRTivLfJxTmbJz9eUcJN3HJL4AEM4hbDtuOGNQiJmWHWfEhafGxaZR8L6MVKGkABleGYmhXCKZNIQ5BPV+5yIyuFKKinXE0LwTCxiCFIwPIAsdum+KO94Qnh/5HbIAVQ24b0bALEaD8vXSVIYiiol982WMIUgCWNAPpxy57qBLn9i09raipEjR2LBggXi1++//378+te/xmOPPYaVK1fC6/Vi8uTJiETkE0FERERERHSwuvyJzZQpUzBlyhTxa0opPPTQQ/jJT36CadOmAQD+53/+B0VFRXj55Zdx8cUXH1xviYiIiIiIBId0jc22bdtQWVmJSZMmpWuBQABjx47FihUrxO+JRqNoamrq8I+IiIiIiKgrDunEprJy3x9VLCrq+IezioqK0l/b37x58xAIBNL/evbseSi7RERERERE/wWOeirabbfdhsbGxvS/igp5gTkREREREZFJl9fYHEhxcTEAoKqqCiUl/5c2UlVVhWOPPVb8HpfLBZdLTonojJz8YrGe7dMTjpqaasW29fVyQkuekLricslJW81NzWK9qEjvX25+gdg2HNMDFkJNjWJbu0NPvgKAYFBPifNlyylLWVl6Eo7FIm83akgIqa7V60vf+pfY1unQk6j20ZNKSsrLxZaBwnytVlUrJ8c1NMnpbOGwkEbVGBLbulx6ckjCIqfEKGXIThLbH3w6TktYTjtp2q2n7tmE5DIAyPIGxHp+fplWSwqJMgCwbOnbWu3jTzeIbW2G5LFwRE+MWr9uvdi2V3mRWM8J6OO5qSEkto206TEvjSG5rWnY9uqtJyrl5srpUi0RIUEoJafxWJWejmiSI1zvAJAwbDsppPdYHPJ5dQk7nnDJ200ZhnM4qt/TUoYEIcBhqB8epuvVIiS8KSXH/9iFxKHmDXoCHgDUv/qGWHe+u0ar+Svk33AICslqe2vltjs/+FSsD/Tpz4O8r50ott20/iOxXr1TT3Lzl+jJhgAQ9OspZcU9B4ptqwzP4q01u7Va9hA9BREAXEWFWm3v8uVi2+a39WMPAKGQPm57XTBVbOs9c7xYj/q8Wi1pPXw/S5aGszKlohkSJ+NCumusWd6GU3g2Gh6NsFkNSW7CjcN0rVls+rEzpbvFwnIqZEK49ThNj21D0qPVob9ttglJpABgtel1m82Qoid1DkAypXcwbngW25RwPJJy24QhfU4J78csphPbTR3Sq6xPnz4oLi7GkiVL0rWmpiasXLkS48aNO5QvRURERERElNblT2xaWlqwefP//d2Rbdu2Ye3atcjNzUV5eTluvPFG3H333RgwYAD69OmDO+64A6WlpR3+1g0REREREdGh1OWJzQcffIBTTz01/d9z5swBAMycORNPPfUUbr75ZrS2tuLqq69GKBTCySefjH/84x9wu+Vf4SIiIiIiIjpYXZ7YfO1rXzOvJcC+30u88847ceeddx5Ux4iIiIiIiDrrqKeiERERERERHaxDmop2NCQs8i6U9dL/Hs6q9+W0rh3b5SSjnBw9vcyTpSedAABahaQtALW1ekJVVracDOV069suLesltvVkyUly2VnZWi0Rl1NG4kI0itstp3sMGCQn0IihJBZ5vnzccSPFejisJ9AsW/6O2NYq7Hdevp5eBwD1NXJaWktNjVbzGVLDmmL6MXI45F+rjAltAcBymH5+YLHLY8AjjKMP1nwstq3YbUhfytHTtrKyPGLbtoh+/hw2+ZqyG45zTo6ezuawyilZkYiceNPYqP9xX5dd3oaUYtjU3CL3LV9OjssO6gl9BT3kxMO2hN7nPRXbxLZBr34NA0AyqV9sUg0AivL1ZCgAiMX1NDi3TT4n9XV6qmBzs/wHlC2GVKBoXN/vYOAQ/FpyF0IFjelnhvYJ4ZjahXQjAGj8SE8Ne3f+w2Jb1/trxXpfIX3Jabi/K4c+nl25cjJeas8usb79nbe0mmeInEJZ/YmcrPb5v97VamVjR4ttB084Q6vZS/SkNADwyIcZ/fz6dZUblO/7jbv2aLXm5R+Kbd1/XSz3w6l3JJQnXyeeY+Vno8PXX6ulDvDbLgcrKaRZJVLys9+akJ9JUvJl1JDAlRUVxq1Hvqqi+m1nX/9a9fYOQwKXI6X3WRnS3VKGxC+rkEpnsRiSHqWEMQAqLtXl4ywljKUM92xTIq1KCMlxhvNqEZLVUgm5bUx+jEIOpTMcC3nTRx0/sSEiIiIioozHiQ0REREREWU8TmyIiIiIiCjjcWJDREREREQZL+PDA2oa9EXAAFBapi+GzF4nLyDcvm2TWM/NK9FqwaC8UNNryBSI19dqNYdLXhgqLWxzOuW2cXEBGxBtDWu1glx9kTMAuL36gswhwweLbZ1ueajs2F2h1Rqb9T4AQFzJq9WGjBio1T7b8JnYtmbvXq3Wo6xUbDugVx+x3iIsmI8bTmBDTb1Wc5jOiVVesCit8zM07ZK4YVFgUY5+vn1+ebFu0+fbxXpt7U6tNnDgALHtmBNO0mobtmwWWgKbt20R61u36e2LhOsPANxO+ecxlZXVWi3apgcbAIAN+iJs07Le3Fz52OXl69dPfqE8Flvb9HCR2io53EIK0wCAbGGMRqPyNeUyhDQ4hWCPaNiwDSF4oaSoSGzbEm4T642VjVqtUrhH7VNmqAtMi1aFoWE1hJnEkvKKZql13WY56GHxnQ9oNf+qtWLbcrvcj9YW/RhVheQbRKVwzbtT8v0oaAjf2PDi37Taju36fRwAQh9/LtYb132i1cLb5PGcbfVrtepS+T5Q6JbDN3Jy9bERMoz9Vpv+bCw/ZZTYNrpxg1i3VOr3v7qdG8W2zs1yvaSvHiqQOIzvuKRcAtMC8dYm+W6XENavC29LAABCLggsdsNdNCnXlZC51GSV710tLfo2fEl5wX2vPLnTqZS+uF5a4A/s+9Mlori+DQjbbd/6/qxCMAUAJFPy9So+mQwvl0wJfY7L+6EMgQ4QtpE0vNdIGs7r0cZPbIiIiIiIKONxYkNERERERBmPExsiIiIiIsp4nNgQEREREVHG48SGiIiIiIgyXuanooVaxHpZkZ6INXjgCLHt6vdXiPWdQlJTjxI5ucfhkJM8UhY9ocWZMKSiQW+bkqJHAARz5HS2gE1P3OhfXCi2bYzpsRjrPvpU3m62vH+FeXriTcoip3ts+UxOFupX3lOrDR2sJ8oAwFtv6+cqFZZTlqyG4d2nj57u1dwkxLMA8Dr0xKK2sDzm3B6fWG+NmhJTDk7ckArUFGrQav1668cYAByGpKalby7Xah+sXiW23blLTxCyOuTkl9Kecj+iQtJMRcVusa3LIae8NDXqCYQ9S+SUMpfDo/chKo+B/v3lPu/aro/nbK98nUSEJLCmkJzoaMmSk2ZcwjF12uXXi0fkZDWV0rfd1iyPZ+me5nHpxw0AwobXc1j1a9DhMqT/yIdDFG+LivUGKfHQJl9//p5yApcjpicArX76T2LbrcL96DhDjJQnT74P24XUyqRTvpeE9uhpYsnGOrFtxCqfq9hufZy3hvT0RwBwZ2WL9WC23r/YZjlZ7dN5D2k1Z7ZbbFta3Fus9540UatVF8lJltuEc9K2MyS27VEn77czqj8b41XyAE20yPFSFuEytkjRZYeIlFtlCr4S3moAAFxe/d4aj8njOSlcgjGnfK1ZEoYUtoT+eh6v3Nbq0/fQcKtEslXe8yT011PKkKAWMaWX6dt2ueTUMJtNv4cmDUl1SUPUWUJIXEsl5WegRbi/J2PyQRJ2Y1/7uLAvhvNnFY6n2ZFLUOMnNkRERERElPE4sSEiIiIioozHiQ0REREREWU8TmyIiIiIiCjjcWJDREREREQZL+NT0WJCshcA1NTraVZFpeVi2/yCrWK9NqRvY/cuOakpS0iJAQCnR08ASsYNkSRCYkrEkDbkccupMimb/nrr9lSJbX3ZeqqMzymnLJUHgmK9tbZJq0VCckpZ2CqnjGz9XE/6GTxkiNh29Ycfa7XGUEhs27tMT8YDgOYmPd3Gb9i/tlZ9/9pq5RSiLJ/8cwIpvOxQ5IO4rXIiSXOoRqtl+eQEoeNGyulzwRx9fK1aLSfmVezeo9XiEXkPSy1ywliPHnr98483im0TETlWpjA/oNUqq6rFtkkh+crnlW+H4RY9ZQ4A9raFtJpFyX3r1be3Vgv65HsGlJxSlkwJaTWGlCW3U05ejIX1+0k8IieMpZL6tkON+j0RAGxOOeksPy9Pq+3avUtsC+htTWxWOUFo7x79Xr7u4w/EtscdL6dk5ln1e2DNB++JbXOFK9nhko+93SLfs4Nnf12vnT5ObLvhod9qtfiSt8W2jYk2sV7j0+/DQ6ecILYde+J4sV77sX6cP1z0uti2pT6k1dpScgLhpk1rxPr7ezZptYHTzxbbTr3wIq3m2CQnttV+tFasR7bq7e29e4ltc3v1E+sW6MfZbulKitTBSxiSr2Ly2wpYHPo9JiHcKwHAbtfHvs1wP3IYUjIjwj3NlpSvbbfweJWvNMBu6IdNSGFLheX9ixr6IQSPIWV43qWk6DglnxRXtpximLQJSXVS5B6AlPDe0pRIp+KGtDvpEabk82cxjmf5mB4p/MSGiIiIiIgyHic2RERERESU8TixISIiIiKijMeJDRERERERZbyMDw+wWuW5WWWNvsA7p1ex2Last7z4L9isL740hRVUVlaK9fzCXK3mEBb4A4BVWFyfTMpBA3V1tWK9uEwPSHD7ssS20pKyZmGxPACs+1xeyG33Zmu1QM9SsW2kWV4UvWrdeq3Wo7+8qH348OFabekbS8W2wewcsZ6fX6DV6hvkBeJ7KrZptZZGOTzA6ZGXMgZ9+qLouiZ5YW9XeLPk12uL6sfZZpUXiBsyBTDq+EFabdDQwWLbT9Z9rtWWvvmu2PajD+XFwUlhcaK07hIAsr3yfg8ZoodFuA2L2rds3K7Vom3yYtFoq7zQOb9Av7Z3b5eDSCIt+qJ7hyH8wWqX988mLBhVCXmRZrhVHl/xsH5Qc4PydSJt2bRYtDZUL9Z9Ab9WKyoqEtvWyxknIqtTfnT1PW6YVmuLyn3btFoOFbDk5mu1ESMHiG0/W62HmbgM2TBh4V4JAJ5++r0uePzxYtvyk07SamvekMMDknE5yKIpV7/ot7aExLYFhrAcW70ewGJ1youfj7vwdK2WisgHad0a/XgCQO4xephMzshRYtumgD6ee54qL/wfOWOaWG8VgoOihgXwqf7ytsN2/VqR4yMODel5njSs7U4YFpTH2vS61ZB0kxLeCtnC8gsmDRuR3k5ZDQvx40rftsXwDtaTkMdXMqXXpZAUAEi1yffWREy4D7vlbViE/RaySfa9npKfPyqhv8dNKHn/4hG9z3YYzknStMBffz2L4SOQlPGjEek1D0VkUufwExsiIiIiIsp4nNgQEREREVHG48SGiIiIiIgyHic2RERERESU8TixISIiIiKijJfxqWimlJ7WiJ4I0xyRUyf8OXoKDgAk4npMT1wORUNNdY1YT0F/TX+2nhQEAHa7nuCklJwkUVsrJ3MVFenJbza7fJqlFJucsp5i20CWnOficOt9bozIKVLepHz8azdVa7UN6zaIbfsN1JOvPinQU84AYPceOdGnrIe+jyUlJWLbHZuFRLmUvB8N1XvFes9cPQXKZjv4nym0QT7OSYc+SH358hiPW+XkpGibPp4tSk4YGzFIP3a9S78htt24UU4Nq6rWk6u27tglto0ZLsItW9dptT695XS9vCL9GtyxWe7b4iXvifUxY0ZqtbIe8nGORfS0wYiQXgcAiaR8ThxCamIwS07ashrS0uxSTJIhebG5We9zo1ADgHgsItYtbj3hLctz8NlQcUO0kDNXvxcc+7XTxLZb3XI/dqz5UKuVlstJbq7BvbVac6OcSFc47WSx7hmnp3u5XPIzYth5Z2u1z1fKCYR7//GWWHck9Pt+xSc7xbYta+V7Wk69fg8sP+FYsW2PSadotc8WPC227R3UEyQB4LjvXKrVrL3lc7Liwd9ptYq3V4ptR35dPiel116t1XyD5PTUiPCMB+SfGlsMz/NDQdqyfCcBYEhklO7wKUN4lhSqFY8YYthM6WxCwlhMSD/b93p63eGRj2dSSBLbtw39XpcwpINZDJ1OCQfE8DYU0ulOGN5Dqqh8H1YOfeNxwzlRcSE5zpS+aTOMxc4/IpBIdWE8G47R4cBPbIiIiIiIKONxYkNERERERBmPExsiIiIiIsp4nNgQEREREVHGy/jwABMpVKCqQV6sW5YvL9RUe/foxZRhUVpSXkRVtbtSq0V98uJSnz+g1exOecF2S5u8cDzU0KjVCoSQAACIRPV+ZAflBZmVu+VFpB6Pvji4LSzvX16uvDC0xq0viv7044/Etr17l2u1oYOHim3fXPamWG+L6P2zGBYslvXVF4zuqpQXtVftkest9fqx82Xlim27orhHoVh3C4EOFv0QAwASCXl5aUmxvgjbYliw2NjYrNXsFnncjh0ln6tsnz72K+saxLYpi3wNtrXqC9hbmsNi2/r6kFarqZSvk3BMXu25o6JCq+Xly9tICYETLmHcA0Brg7wQvy2mbyPVFhXblheXivWWNv3+EI3K2/B5vFpNGVYSS0EDANDWot+nrKaVqAga6gLDal0L9GPqcMnbHXiCHCrgzNIDWNrq9XALABhwkz6eg7k5Ytv8YQPFui2o98+0oDm3Xy+tNuXnd4htX2qVF7VHVq3XXw/yOfm8rVas+5V+nPOCcqDDR+++o9Vq6+Vgl/wC/f4OAPXSc+04+V4y/MzJWq2uQX5eWu2GG6NQthkW/nsN9yNp8blpkXlXWCzy2zabcJO3GtZ2my5Bm3CTdxp+/J2E3lZavA4ANqu8EWnxvxJjEACPQ9+GW1hYDwBJw0J8t7AzFsM9LS4EGwBAPKpvI2lomxICD+x2+Vi4DavrExZ9X+wW+fWk4x8Xvh8AYm2G19Mf5xAePQCAsDGdQmc5gp+j8BMbIiIiIiLKeJzYEBERERFRxuPEhoiIiIiIMh4nNkRERERElPE4sSEiIiIiooz3H5uKZrXpCSFNbXJaVzylp/8AgDegJzVVV4bEtnaHnALV2qynseyokZNmcvLytVowNyi2jcTkJKOdO3dqtUCuvl0AaInqffv040/EtoP69hHrUaEfLqecjlNTUyXW8wv1tLRP130utv1svV4fPGiw2PbD4Bqxvmu3nl7Wf+Awsa07ru9fXpmeTAQA1bV1Yr1yt56e1W/owaeiRZqF+BIAzQ16VIndLiegOF3yuA3Z9J95mMa4EtKC6urlc+12y9eay6OPmdyAnDCW5c0W64m4nm7jcsmvt3OHfk5aQnLyVe/e8ti3WfWoGLtDTquRjn8kLCc1ZXmyxHo0pSe81dfLyXFZdj2tEACCXp9Wc7jktuGons6WNKR1udxynyNR/Ri1tcoJarAH5brU1JD2JD3QlJJ/fmcVUt8AoN/oMVotGZeT8WzSNWF6qhr6nJK+YIogTOlte40YITY945qZYn3Jhru0WqhWT+8EgKBLTg3zC6lT2199XWxbGAhqteJjBohty086Uaz7epVotZRDHrfFp0/UaycdK7ZNBuT9c2QFtZrVkFoFY/3w6O2XX29UiT42jvHLg87hMIwvIeHNbUh9E5P7DGldhuw5uLzCtg0/brcm9f2OReT9sCTkfmTl69uwWQ3PRkNynCeht08J1yVgSMEzHKOUVX5BKcEuGZG3YW3T6zFDYlusVd7vWKt+TJOGe1rfoLyNbXH9jNcIfTtc+IkNERERERFlPE5siIiIiIgo43FiQ0REREREGY8TGyIiIiIiynhdmtjMmzcPJ5xwAnw+HwoLC3Huuediw4YNHdpEIhHMmjULeXl5yM7OxvTp01FVJS8kJiIiIiIiOhS6lIr21ltvYdasWTjhhBOQSCRw++234+tf/zrWr18Pr3dfwsxNN92EV199FS+88AICgQBmz56N8847D+++++5h2YGuUIbkioZQi1jPz9HTxHZX1ohtrYbAB5eQOFSzZ6/YtqVZTwtqbsoR21rscs5IY6OetFRSVi629Qb1dKlwWE9eAoCmJjnJKBLR2xcUFoht43E9rQsAXE79GGV55ZSldevWabU+feTUqmHDhov1lxe9otXcfjk5LlCgH/+yPn3FthXbt4v1UI2eOLS7Qk/lAoBjh5aJdUmeXx4bObl6mt/mzRuElkBDo5zQ5/fqiVE1DXICl3RZ+f1ycllrq5xM2NBQrdV8hvSzpCFiJxHX42Maa/XtAnICWnlPeQz4goY0uISeHhOLyddPltut1bK98vlra5YTDxMWPZnL79PPNQDEhb4BwNYdempiWZk85mx2fb+VVT74niy/WG9q0e9HNdXyObGUyvcpiel+KzeWk3uUMcxK37jVJj8qk0IiIAyBU4ZuiJladot8nJPQU+bk6CUgp6xQrLuy9bHoq5IPaKlNvg/3zdLv2XYhRQ8A3GH9umxdv1ts65ig9w0A8gf01mqpgNw3JSTV2YLydq1S5BQAa6rzaV1Hmtswjka69IFXYJUHo2GIwipcWHFTSpkQfmq4TCDcSvZtw6bvjMUQH2iHfq4shuQyQ5AbYsLDypR2J/UNACxOve4UUngBwCrEN1oNiXTKFITYqNfiQjIbAMTDej0ZMRwMOVQQ2UXCtuXLB2fEDKmCwiZe2Cncuw6TLk1s/vGPf3T476eeegqFhYVYvXo1TjnlFDQ2NuKJJ57Ac889h9NOOw0A8OSTT2LIkCF47733cOKJcpQjERERERHRwTion0E0Nu6bSubm7vubHKtXr0Y8HsekSZPSbQYPHozy8nKsWLFC3EY0GkVTU1OHf0RERERERF3xlSc2qVQKN954I8aPH4/hw/f9yk9lZSWcTieCwWCHtkVFRaislP8A2Lx58xAIBNL/evbs+VW7RERERERE/6W+8sRm1qxZ+PTTT/HHP/7xoDpw2223obGxMf2vwrD2gIiIiIiIyKRLa2zazZ49G3/729+wfPnyDgtPi4uLEYvFEAqFOnxqU1VVheLiYnFbLpdLXGB/OFgNqzdDLfKC5lxhcX0wT14k21AtJ79lO3xazZslr8SqrNRDBWIxeUGmwy2s3AMQT9VptY0bN4pthx47TKu1teqLfQEgLIQEAIDbrZ+7PXv2iG0DgaBYdzj1fSkpLhHbrv9MXwS/fv16se3QoUPFenGRvqi2pkpezLp+40darWLnFrFtvE1Y5QfAk6UvclX2gx/zdqu8DbdTX/hfUmT4JNQir1j0BfVx63DJi3UjwqJhq1X+mUlNjSGswKe/nk9YoAwAba3yr6u2tOhj1GqRb3FF+frCfX9SX5wPAPUtIbHuEPYxyysv5nc69Wu+rlYOY2hukMNMCvP0UA5vjn6uASBsuI5h1Y9HyPDrv26PR99uWD5Gbq9+/gAg16nfQ0Mt8jYMPRZJa7sBw0/qTIv2DYvuJaasgnjnNwHD+mnYuhCE0JU+JxPyYl2vcJTshvuROyavzvYr/Zp3OgyLvj366xWefIrYts/Z58jbyNGvV4thECSFBeJJw33OlZT7bMjI6Baa43KfY8IuOgyDP5mSz6tdCBswhV5Ih8hwmJGMyffhlLBt4Rb1740LfTCEIxjW8kMJqQIp07k23jeEY9SFgJKEkl/QYrgRuIVHisdvCBcJ632zmUIJDMELkbDej5YGeSMJQ4hBa1jvn9C1w6ZLn9gopTB79my89NJLWLp0qZZGNWrUKDgcDixZsiRd27BhA3bu3Ilx48Ydmh4TERERERHtp0uf2MyaNQvPPfccFi1aBJ/Pl143EwgE4PF4EAgEcOWVV2LOnDnIzc2F3+/H9ddfj3HjxjERjYiIiIiIDpsuTWwWLlwIAPja177Wof7kk0/i8ssvBwA8+OCDsFqtmD59OqLRKCZPnoxHH330kHSWiIiIiIhI0qWJjZL+GNl+3G43FixYgAULFnzlThEREREREXVFN/lbukRERERERF/dV0pF+08TN6Q1NLREtVpRcZnQEqjeLSeBtSk9qcmXExTb1tRWa7Vwi5ycFJdDysSUig0ffiC27dFDT6pzeuTEts82yMlq4yeM0WrKkFQSDsvpc5FWfWeK8vUEKACoyNqh1T5Zs1ZsG6quF+v1e/UEu9Ufvy+2DcdiWi07qCf0AECuKXnMqqe+hQ1pIl3RKgfmIVXTrNcM0S9uj5x0Fo7on85arXpKFgColJ5ylZWtp2EBQK9efcR6Iq4f52hMv/4AwO4wxNhIh9Qif8rcFtEzuCxOebsFBfL5TkT1/d69S082BACnTb/VJg2JU7akPDbqavR7gSVf/tmU3SZncDnd+vWdMsT/hKP6OWkRrlUAqK6Xk9ziQjCXwymPo+7MdLV25QHapZ8iGl6wCwFqyPIYEvqE+5e7Sn/2AEBAyQl2LuG8qtx8sW32+VO0Wq+rviO2tfftLdaVkHRmlyK1AFiEo5QypMkl5XDRbv0TXyXmkQFK6c/duBSVBiBpSqiSbhsW+fXswuD3uOUR6pQGDACrXTivhvhAqRtCyBkAwGaXv5ASfutIGa4q028oGfLkxKpFGqOG7ZqS1WxCxJvwOAEAuNx679oa5NdrrDTst/DYtcTkMeDPk/th9QsDrOrIRQ125+uXiIiIiIioUzixISIiIiKijMeJDRERERERZTxObIiIiIiIKONxYkNERERERBmPqWiAMVqjoUlPTirJKRLb+v1yctKePbu1ms8jpwJl+7xarb66UWyrknLKiJQ7UVe1TWy7Y8smrdZ/yDFi20RSPkbr1utpaccMHyq2Leorp+YoIaLlk7WfiG1bQnoy1NbtO8W2//jnP8V6W0SPE/N4XWLb/GI96czq1s8TADQbks5SQqKPzZCA0hVbd+rpbgDgcgoJXCk94QoAfH45vczh0M+30y6nmng8+rETQs4AACol33KSQrJaU6ucoueQ4ngAtArntaxHubwNp97n6no5GSqZknNwrFa9H8VFpWLblkZ9XxqbQvLrhfX7DgBYs31aralRT8ADgHBYTi+LRIWkxyL5ugx49bERCMopWfEGuc9VtTVaLdS4S2xbOFLuh+Tgr55D45A8QLuwM13Zb2dQjiyyFQn1LfKWc51yaqIrrN/Twjl6yiYAFH9jqlbz9JETJFVKjuuyWIXnj+HHslbhKLm7zYg5eClDGpxSel24Re1ra0helA5q3PDsj0T0+2IyKidt2a2GJDChf4bbO6zCI9pqCNpyOA2JkzZ9v212+VjYHXJdCDmF1WYat0JbQ+qbMZ1NeP5EWuWNxITbsCUu74fDkBgqvbM0JWdK720AIClcx1ZDMuvhwE9siIiIiIgo43FiQ0REREREGY8TGyIiIiIiynic2BARERERUcZjeAAAWOSFUfGEvlC2pUVerFtW1kOsb96sL9CPGLbhdUsLwuRFaUlDXVqTHou3iG23bNEX/pf26i+2tRlWITbX64uUq/fWya+3cYtY37DpM73t53Lbujo9PCBmOH/uQFCs5xQVajW7zS22TSh97q8MiymVYYGdxSKfq4NVF5IX19fX6YvgXS75/Llc8iJEu7DIMiCEWwBAobD4vMghL1y2O+Tj7BSOXcoQVtDaKi9UT1n09nur5bEojefsoBzq4XQbwgoa9bEfj8nnOhIW7iXNetgBAOR45WOUlaX3z+WS2zY1y/cYp0tf+RpPyAttG5v1+4Y/mCu2TUI+dlXVTVrNYlrRTJ0g3WMMC7azhFXOALx5Qa3WbFhLbpUW7QOwu/VrzeqRXy9lEcaXMt0TDQuMpV38z8kD6BJpYTYAxOLCQTIs7jaUxS/YbfL9wekQ2hoWpFsNP0O3CO2Tps5F9BNuWnCfkh+NsErvFYRnHQBEYvK2hdwZuN2G92PCti3CcQMAu5xfBJt0ScQN4VHCtWYzbDdh2G8ovX/SeQIAyENDDBswvG06LPiJDRERERERZTxObIiIiIiIKONxYkNERERERBmPExsiIiIiIsp4nNgQEREREVHGYzzNAVgt+rwvFAqJbQuD2WK9SEjg2rFVT0oDgGxPQKs5nXJKTCImp2JIgSKmtK5YPKrVaur2im0L8wvEel1Vo1Zb//FasW1NSE6oamnTU66shvQsb16JVgtky8ceNjnxSykhgUuomZgCQqyGhBaxeggSffZU1oh1W0xPs7KEDeNFitEDkLDrCUeN4ZjYtiqkv16tkBgGAD17yOmBboce3WJLyH1OtMrnNRLV96W6RU5Qa27U0/Wq9u4S2/q9WWI9y633OT9Xv4YBwC78CEml5OSyqMUn1ttS+vXqdfrFtqXFpWJ9w+cbtFosIh9nj0/vR8Aqp5/V1spjsbamUqspMeaHOkMKdUoJKUYAAMOzIyuon9cGw70rGpOvebddvyZyepeJbbN799SLhrQ1U8oSfwT7f1KGRNRUSjjfKVOCpyGVzirUhWRQALBIiaHS95s3AYvw/LHY5LEoPals1q7dS6Trx2qT++wSUjb3EZLckqZzIiS56bdxAEAibEpVFXqg5AvF7hAaG97lJxPy6yWFTSeT8jlJyLcHJIT9Th7BFEPeLoiIiIiIKONxYkNERERERBmPExsiIiIiIsp4nNgQEREREVHG48SGiIiIiIgyHlPRAFgMiTA2YdoXDstpTzua9ZQlACjuoSfF7Nkjpy+Fo3Gt5vJ4xbbJlJyK4fcHtZrVKW8jLy9Pq9VVVYltK7ZtFuvhNuF4GNLI7B45wSmnpEirOYTEKQCwCGk6yhS5Ykg6k1LNjCkx0vcbxosh/8zg4H+mMGrUILHeI6gnyiUjenIZANgM6USb9tRqtWXvfyy2dTn1811TIyfg7dgmj/1Atj5GexYExbY2l5yYF2rV42Yam+RUtLrqaq1WXFAsti0p1JMNAcAlJNDkBOTUML9PGM+GeL2ERb4tV+7V+9zQGBLbBn1BsZ6Tk6vVdlfLiWate/V6Xr7+/QBQY9hGOKL3z50tJ8fRl7MIEUnmVDQ92RAAbEH9+CtDulQqoT+TACDh1JP0Ils2im2Tz/1Zq/Wc+W2xrdWQvmkTUplshmjJhHBLSxmuNYcUIwr5OIvxVEeBMpzvhFCPRuRtGIIQ4RBuPVa7/Hp2Ycg47YZnruGdprQvpqOclIao4bxarXJdCokzBaI6XPJ7AinJzZTyJw4jU0KcXBa/Yk40E+4PhqTBuGFsJIRtpwyvZ4kbxqL0mqb71GHAT2yIiIiIiCjjcWJDREREREQZjxMbIiIiIiLKeJzYEBERERFRxmN4AMyLwa1KXzyWSMir7hpNi3iL9IXHOQXyYuS6Pbu1WlGO3LakrKdYl9Z4VdfIwQY1tfoCb19QXiQWTcjHKKugXKvZDdPl1pC++BkAmir0BeXKsKjT4c7Wav5cPXwAAFxen1hXwuo91YWFoeYlcJ3fxqFYhhrIiol1t1tfZZlTLI+jvdXyIv/sHD3oYcLJJ4ltG+rqtVrVnr1i24rtW8R6lUMPINizRw69cHrlerMQ7FGYHxTbDhrYS6v1Leshts3L0UM2AMBq0e8FsXCz2DYe00MMWlvktnanPsYBwJLU70fRpB6YAADOQjlgwenTj52rTV5F2pps0mrbd+0U27rdcmBIbklQq7W0yX2mThDuUyolL3K2Ge5/BcOGabWdOTli2+bdctiHzaq/pscwNqLP/lWrRcaeKLZ1TsgX68KjGFbDqu+4UI4bFpnbDSurLVKYQjcJD4hLBwNAVHhmpixyW9OC+aSQFRGNmsJ59NfzyLcB2GyGMSq8A7WbtiGEGCjDO1irzbCDdqEfhsCDpCE0wSIEDdkMY0MJIQbK9HmCoWyzSQELhuCMiNDWsPA/YVj4n+pCAIEpuCmZ0rdhMbynOxz4iQ0REREREWU8TmyIiIiIiCjjcWJDREREREQZjxMbIiIiIiLKeJzYEBERERFRxmMqGgBliAhJCelZSUOyQ9IQ+BCL68lJhUVyildrvZ5Q1dCoJxMBQHPUJdYTQgqHI1tOWfL69CQch0dPwwKAQLacsNPUoCdi7dqzQ2wba9HbAkC2Uz/+Lo/8eomwnkjSUisn1bncfcS6ckipWkcuseNQsaXkNKttW/Qko1C+nIq2qaJKrG/fXavVjj92rNi2d49SrbbRId9a6jxyWpfbrdcd2XL6WcKQeJMnvObIoX3Ftn6nPo5aG+T0wPp6OX2uIDeo1bxZ8nXZnNBT0fyGdLdwmxxBkwjraWLNETlh7MOP1or16np9H+MpIQEKQKixUau1tcn3oxNPOl6sDx3WX6vV1+vbBYDNcmgifQmrIZEpabin5Q8dpNUcI4aIbXdWVIh1R0x/NjpiQqQWgIBHH8/JjdvFtvbjhop1ZAnXipDeBAB2ITFKmXIou0nSWVc4TX1O6eckbEgzNaWiWZ36NixCwtW+upD4Jbz/AICU4WfoSnjjlBLS1gDAJjzmLYa2ytRnq94Pu3zLBgypaDYh9tXpNqS4OoU+CClnAGAT+gYAViHRL2FIKYtH9f22JeXtJgwbSQkpi6b0M9Nxtkrvk4/gpcZPbIiIiIiIKONxYkNERERERBmPExsiIiIiIsp4nNgQEREREVHG48SGiIiIiIgyHlPRAGMySkqo25xyhIYp9aM5oifF2J0esW12boneNciJRS6fnBrm8GUJ25D3LxEOa7VIs5xY5ErKCVyJ6i1azeeQ++wbcpxYt/rytZrdKm/DCz0FKtwop62phJxmZXHoxyjzMtEAl1XfDwCwW/UEoa3b5MipygZ9DABAfV2zVvtg5bti27JSPRUt2yMnfvUu08c4ADQ1CWlbDnncxpNymsvGDRu0Wk62vI2B5fqYU0oeL82NLWI90qpfK/369Bbbuhz6fSOp5P3wZTvEOqx6vW33HrGp3SHfj/Ly8rSaw5BA2NPSU6v5A/K9q0eZfjwBIJHUx1dpjwKx7eZq+TjTgVkNaUoWQ+qRT7gG+33zG2LbZZ9+Jta3b9KTL/tLyWUArJE2rdbw9zfEtn2O6SfWvaOGa7WURYicAmBXnX9bYxGST//9hU5v40hzG5LArHrwIiJxeT/ChgeeRbj1eA2pYS6rkD5nOmyGtDSLdKqE7ZoZtmvRk70AwCG8r1CGlLLGVrkfNiEJLJBtSGcTQkCtTkOyrk2+Xm3COUkI6WcAkBLSCpGUj0UsZjjOwvGwu+Q+J6LytnOFgESP6Vo7DPiJDRERERERZTxObIiIiIiIKONxYkNERERERBmvSxObhQsX4phjjoHf74ff78e4cePw2muvpb8eiUQwa9Ys5OXlITs7G9OnT0dVlfyXzYmIiIiIiA6VLoUHlJWV4d5778WAAQOglMIf/vAHTJs2DR9++CGGDRuGm266Ca+++ipeeOEFBAIBzJ49G+eddx7efVdedNx9GBZiCYv0HMIiYABw2IVVYgDCLfrCSY9hkWVuaS+9Z9JqPgBxw4LRmLBAy5aSF3553XpbZ5u+aBwALGFhZSKAop4D9dfz+sW2YSXvS0QISIgYFoBahYWFvlx54XJbRF4MHlPCgrcjuLDtUAkGi8S615uj1dwNwuJ8AHavHAqRm6Mv8M42LHqsqdaDCaLN8jgqzNEXrwNAtke/rlKGu1OosUGsJ6L6tZadJV+XduH6cRiuy6RhgaQUcFG9t0Zs63Xr/XC7s8W2NfXy/lXX6SEZptALt1NeWB2J6Av0rUiIbQsK9evK5ZJDPRIxPdQDAJxC+8YGOewDkPtMX43NcE9LuPTjPHTKJLFtuLpWrH/y+B+02vZaeewHbfr4KnPLF7fbZbjvQ78GU0JtX1v9qrAanvGm8gG+cNTVJuWrfnGzvvg8xyWPgaqo4f1DSj+mJXZ5UbtXuBUYMksQMATB5Atvp4JOeSN+KdjALfcty/Cssgj9MAUNBOTbM6wWfdumtw+ppP56hhwmcdE+AFiFhfhJQ3iAEl7PkFEjhhIAgMOm70wyLvctHpPrduGQ2o5gRFOXJjZnn312h/++5557sHDhQrz33nsoKyvDE088geeeew6nnXYaAODJJ5/EkCFD8N577+HEE088dL0mIiIiIiL6gq/8Y+pkMok//vGPaG1txbhx47B69WrE43FMmvR/P/kZPHgwysvLsWLFCuN2otEompqaOvwjIiIiIiLqii5PbD755BNkZ2fD5XLh2muvxUsvvYShQ4eisrISTqcTwWCwQ/uioiJUVlYatzdv3jwEAoH0v5499b+dQEREREREdCBdntgMGjQIa9euxcqVK/G9730PM2fOxPr1679yB2677TY0Njam/1VUVHzlbRERERER0X+nLq2xAQCn04n+/fsDAEaNGoVVq1bh4YcfxkUXXYRYLIZQKNThU5uqqioUFxcbt+dyueByGf60LRERERERUSd0eWKzv1QqhWg0ilGjRsHhcGDJkiWYPn06AGDDhg3YuXMnxo0bd9AdPbzkVAwpd0IISgMAeD0esR4L60lNyi2nhqUsesxISkgpOVBH7EJSiV0JsRoAmqv1XxFsa24U2+b3KJf7YdOHkCUlJ3b4nHLdk5LSy+REMynQrCkix36krHIilnScLUcwseNQqW+uE+uWpH6+E/Gw2NafLf9QIS9XT1wLZMlte5XqP7goKZJ/mBELy5EwrUKKWiwhJ/Flu+VkrmMG6wl9hUVyClssqr9eKiIne+UE5G04hLFfXyOnSDVUhbRav3//gGh/Nrd8nO1Ccly+LyC2bW7U088AICkcf09AToPzuqTrVU5Qi4flY9dQrR9nf9AntmUq2qFluA0jJaRq2dzysT/hsvPEetmIflpt0+tLxba5QgJh0QnDxLaWnCyxbhf6nLTLO5gQyvIdoztnn5lFDG8JNkaFZ1jUEIkFU123R3770EWG9ytCLUtIPgUAn5DWlWuXf+moULx3ASUevV7skd8GFxhSw7Kd+glwuAwnRUqOM/TZ/OtTwtg3XdzS/dlwPB2GZN09zXqnVzfJ+9cYl+s7hNS9lu6ainbbbbdhypQpKC8vR3NzM5577jm8+eabeP311xEIBHDllVdizpw5yM3Nhd/vx/XXX49x48YxEY2IiIiIiA6rLk1sqqurMWPGDOzduxeBQADHHHMMXn/9dZxxxhkAgAcffBBWqxXTp09HNBrF5MmT8eijjx6WjhMREREREbXr0sTmiSeeOODX3W43FixYgAULFhxUp4iIiIiIiLoi8/7cOhERERER0X4OOjzgP4F5AaGwaMuw/snukheqR2P6yruWZnlhrztLXzhpsxmWPRo6bQnrf+A03lQjtk0l9L75S8rEtvFseYFx0qIfEKsh2MASkxceW1JCeyklAHLMg7LIw1hl5NLQznN45OMcadHHV7ZPHke5Xnnc7qzQgyVC1XKgQ5ZLCM4QxhYAxAwL9K3CmS3KkxeZWyHXa1v0sIHaKnkc2a16PdyoL3QHAE+xYXG9W9/vYDBfbBtz6ov2m1r0YBEACMXk+0NCuCZyfdli27LiHmK9R74eCtESC4lto216PRqVz6vDIQceFOYV6kXTSm46pGyGe6hVWGAcbpVDY2ordoj1uvoqrVYwQA6YKQnoARepAvk6iSbke5pb6T+DtRoGknzfNzy4LYZF3+LPfP+znydHg/SOoEnJwQZNcf0c7hZqAICIIaygSR8zWRb5vOYY3h33cOlfGJ4tj6MCp76HbsN2s21yn6X3U4bLRMpygl16fwWgrVX+XONN4Ri93SJvI2q6JsR7z5ELD+AnNkRERERElPE4sSEiIiIioozHiQ0REREREWU8TmyIiIiIiCjjcWJDREREREQZj6loALqS1pAyzAWVTU4FcupBZ0i1hsS2yUY9mcbqcMr9MCRdpBJhrWazy6fZF9ATi5JSwhWAiCH8QkrsMM2WraZtdGV6LSSYKGWKiJPrliOYznE41VSHxLovWx90VsMYaG3W07oAICfbr9WycuQEtVhcT0vzB+S0rrawnGS0c2eFVqusqRPbhsNysprPr/cZcTmtJh7Tr5P8vFyxbXObnF4WTemJN8qQRNUc0dMK7SmH2NZtSDqrCzVotURSTimLJuRjlLTqiUOJmJxCFAvr+2exy332BvPEela+nn6Vgvx62K7vH311pvutdMO1WuX7g80pPw9ye/XRap4+8gt6vHqqoCtXHi824b4DABabfu+xmJ7FXaimDHWrWGcq2hFhfDybEuw6v42EkLim35n/XTfcpnZE9fviajnIElnC484QUIr+bnl8jdFDBdFDfluIiPA4V0n52v4wLB+kd1r053nX0s9wJAPQRPzEhoiIiIiIMh4nNkRERERElPE4sSEiIiIioozHiQ0REREREWU8TmyIiIiIiCjjWZQSYq2OoqamJgQCAdx6661wueSkMSIiIiIi+s8XjUZx7733orGxEX4pAfUL+IkNERERERFlPE5siIiIiIgo43FiQ0REREREGY8TGyIiIiIiynic2BARERERUcbjxIaIiIiIiDIeJzZERERERJTxOLEhIiIiIqKMx4kNERERERFlPPvR7sD+lFIA9v2VUSIiIiIi+u/VPidonyMciEV1ptURtGvXLvTs2fNod4OIiIiIiLqJiooKlJWVHbBNt5vYpFIp7NmzBz6fD83NzejZsycqKirg9/uPdteoi5qamnj+MhzPYWbj+ctsPH+Zj+cws/H8dQ9KKTQ3N6O0tBRW64FX0XS7X0WzWq3p2ZjFYgEA+P1+DqgMxvOX+XgOMxvPX2bj+ct8PIeZjefv6AsEAp1qx/AAIiIiIiLKeJzYEBERERFRxuvWExuXy4W5c+fC5XId7a7QV8Dzl/l4DjMbz19m4/nLfDyHmY3nL/N0u/AAIiIiIiKirurWn9gQERERERF1Bic2RERERESU8TixISIiIiKijMeJDRERERERZbxuPbFZsGABevfuDbfbjbFjx+L9998/2l0iwbx583DCCSfA5/OhsLAQ5557LjZs2NChTSQSwaxZs5CXl4fs7GxMnz4dVVVVR6nHdCD33nsvLBYLbrzxxnSN56972717Ny699FLk5eXB4/FgxIgR+OCDD9JfV0rhpz/9KUpKSuDxeDBp0iRs2rTpKPaYviiZTOKOO+5Anz594PF40K9fP9x11134YrYPz2H3sXz5cpx99tkoLS2FxWLByy+/3OHrnTlX9fX1uOSSS+D3+xEMBnHllVeipaXlCO7Ff68Dnb94PI5bbrkFI0aMgNfrRWlpKWbMmIE9e/Z02AbPX/fVbSc2f/rTnzBnzhzMnTsXa9aswciRIzF58mRUV1cf7a7Rft566y3MmjUL7733Ht544w3E43F8/etfR2tra7rNTTfdhFdeeQUvvPAC3nrrLezZswfnnXfeUew1SVatWoXf/va3OOaYYzrUef66r4aGBowfPx4OhwOvvfYa1q9fj1/+8pfIyclJt7n//vvx61//Go899hhWrlwJr9eLyZMnIxKJHMWeU7v77rsPCxcuxG9+8xt89tlnuO+++3D//ffjkUceSbfhOew+WltbMXLkSCxYsED8emfO1SWXXIJ169bhjTfewN/+9jcsX74cV1999ZHahf9qBzp/bW1tWLNmDe644w6sWbMGL774IjZs2IBzzjmnQzuev25MdVNjxoxRs2bNSv93MplUpaWlat68eUexV9QZ1dXVCoB66623lFJKhUIh5XA41AsvvJBu89lnnykAasWKFUerm7Sf5uZmNWDAAPXGG2+oiRMnqu9///tKKZ6/7u6WW25RJ598svHrqVRKFRcXq/nz56droVBIuVwu9fzzzx+JLtKXmDp1qvrOd77ToXbeeeepSy65RCnFc9idAVAvvfRS+r87c67Wr1+vAKhVq1al27z22mvKYrGo3bt3H7G+k37+JO+//74CoHbs2KGU4vnr7rrlJzaxWAyrV6/GpEmT0jWr1YpJkyZhxYoVR7Fn1BmNjY0AgNzcXADA6tWrEY/HO5zPwYMHo7y8nOezG5k1axamTp3a4TwBPH/d3V//+leMHj0aF1xwAQoLC3Hcccfhd7/7Xfrr27ZtQ2VlZYfzFwgEMHbsWJ6/buKkk07CkiVLsHHjRgDARx99hHfeeQdTpkwBwHOYSTpzrlasWIFgMIjRo0en20yaNAlWqxUrV6484n2mA2tsbITFYkEwGATA89fd2Y92ByS1tbVIJpMoKirqUC8qKsLnn39+lHpFnZFKpXDjjTdi/PjxGD58OACgsrISTqczfVNoV1RUhMrKyqPQS9rfH//4R6xZswarVq3Svsbz171t3boVCxcuxJw5c3D77bdj1apVuOGGG+B0OjFz5sz0OZLupzx/3cOtt96KpqYmDB48GDabDclkEvfccw8uueQSAOA5zCCdOVeVlZUoLCzs8HW73Y7c3Fyez24mEonglltuwbe+9S34/X4APH/dXbec2FDmmjVrFj799FO88847R7sr1EkVFRX4/ve/jzfeeANut/tod4e6KJVKYfTo0fjFL34BADjuuOPw6aef4rHHHsPMmTOPcu+oM/73f/8Xzz77LJ577jkMGzYMa9euxY033ojS0lKeQ6KjJB6P48ILL4RSCgsXLjza3aFO6pa/ipafnw+bzaalLlVVVaG4uPgo9Yq+zOzZs/G3v/0Ny5YtQ1lZWbpeXFyMWCyGUCjUoT3PZ/ewevVqVFdX4/jjj4fdbofdbsdbb72FX//617Db7SgqKuL568ZKSkowdOjQDrUhQ4Zg586dAJA+R7yfdl8/+tGPcOutt+Liiy/GiBEjcNlll+Gmm27CvHnzAPAcZpLOnKvi4mItCCmRSKC+vp7ns5ton9Ts2LEDb7zxRvrTGoDnr7vrlhMbp9OJUaNGYcmSJelaKpXCkiVLMG7cuKPYM5IopTB79my89NJLWLp0Kfr06dPh66NGjYLD4ehwPjds2ICdO3fyfHYDp59+Oj755BOsXbs2/W/06NG45JJL0v+f56/7Gj9+vBavvnHjRvTq1QsA0KdPHxQXF3c4f01NTVi5ciXPXzfR1tYGq7Xj49hmsyGVSgHgOcwknTlX48aNQygUwurVq9Ntli5dilQqhbFjxx7xPlNH7ZOaTZs2YfHixcjLy+vwdZ6/bu5opxeY/PGPf1Qul0s99dRTav369erqq69WwWBQVVZWHu2u0X6+973vqUAgoN588021d+/e9L+2trZ0m2uvvVaVl5erpUuXqg8++ECNGzdOjRs37ij2mg7ki6loSvH8dWfvv/++stvt6p577lGbNm1Szz77rMrKylLPPPNMus29996rgsGgWrRokfr444/VtGnTVJ8+fVQ4HD6KPad2M2fOVD169FB/+9vf1LZt29SLL76o8vPz1c0335xuw3PYfTQ3N6sPP/xQffjhhwqA+tWvfqU+/PDDdGpWZ87VmWeeqY477ji1cuVK9c4776gBAwaob33rW0drl/6rHOj8xWIxdc4556iysjK1du3aDu9potFoehs8f91Xt53YKKXUI488osrLy5XT6VRjxoxR77333tHuEgkAiP+efPLJdJtwOKyuu+46lZOTo7KystQ3v/lNtXfv3qPXaTqg/Sc2PH/d2yuvvKKGDx+uXC6XGjx4sHr88cc7fD2VSqk77rhDFRUVKZfLpU4//XS1YcOGo9Rb2l9TU5P6/ve/r8rLy5Xb7VZ9+/ZVP/7xjzu8keI57D6WLVsmPvNmzpyplOrcuaqrq1Pf+ta3VHZ2tvL7/eqKK65Qzc3NR2Fv/vsc6Pxt27bN+J5m2bJl6W3w/HVfFqW+8KeNiYiIiIiIMlC3XGNDRERERETUFZzYEBERERFRxuPEhoiIiIiIMh4nNkRERERElPE4sSEiIiIioozHiQ0REREREWU8TmyIiIiIiCjjcWJDREREREQZjxMbIiIiIiLKeJzYEBERERFRxuPEhoiIiIiIMh4nNkRERERElPH+P9fA6vToS9dnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CIFAR100"
      ],
      "metadata": {
        "id": "Gm8qgTn81sc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "-qTTHSBHgd1k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bllMDS9LAIyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare CIFAR-100 data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained ResNet50 model and adjust for CIFAR-100\n",
        "print('==> Loading pretrained ResNet50 model..')\n",
        "net = models.resnet50(pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 100)\n",
        "net = net.to(device)\n",
        "\n",
        "# Fine-tune the model on CIFAR-100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Starting fine-tuning on CIFAR-100..\")\n",
        "for epoch in range(25):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(trainloader):.3f} | Train Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "# Define FGSM and PGD attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "# Carlini-Wagner attack function\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Test function to evaluate model accuracy on clean or adversarial examples\n",
        "def test_adversarial(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    if attack:\n",
        "        print(f'Accuracy on {attack} adversarial examples: {acc:.2f}%')\n",
        "    else:\n",
        "        print(f'Accuracy on clean images: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Evaluate on clean images\n",
        "print(\"==> Evaluating on clean images..\")\n",
        "acc_clean = test_adversarial(net)\n",
        "\n",
        "# Parameters for FGSM, PGD, and C&W attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Testing the pretrained ResNet50 model on FGSM, PGD, and C&W attacks\n",
        "acc_fgsm = test_adversarial(net, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial(net, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial(net, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pretrained ResNet50 Accuracy on Clean and Adversarial Examples (CIFAR-100)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "7vT4gNPQgYXW",
        "outputId": "c4e4156d-44c8-418d-fbeb-19ad31ec9f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> Loading pretrained ResNet50 model..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 202MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Starting fine-tuning on CIFAR-100..\n",
            "Epoch 1: Train Loss: 2.736 | Train Accuracy: 44.12%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-21972aa6f10c>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19"
      ],
      "metadata": {
        "id": "6sZx37PKg6xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare CIFAR-100 data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained VGG19 model and adjust for CIFAR-100\n",
        "print('==> Loading pretrained VGG19 model..')\n",
        "net = models.vgg19(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(net.classifier[6].in_features, 100)  # Adjust final layer for CIFAR-100\n",
        "net = net.to(device)\n",
        "\n",
        "# Fine-tune the model on CIFAR-100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Starting fine-tuning on CIFAR-100..\")\n",
        "for epoch in range(25):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(trainloader):.3f} | Train Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "# Define FGSM and PGD attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "# Carlini-Wagner attack function\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Test function to evaluate model accuracy on clean or adversarial examples\n",
        "def test_adversarial(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    if attack:\n",
        "        print(f'Accuracy on {attack} adversarial examples: {acc:.2f}%')\n",
        "    else:\n",
        "        print(f'Accuracy on clean images: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Evaluate on clean images\n",
        "print(\"==> Evaluating on clean images..\")\n",
        "acc_clean = test_adversarial(net)\n",
        "\n",
        "# Parameters for FGSM, PGD, and C&W attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Testing the pretrained VGG19 model on FGSM, PGD, and C&W attacks\n",
        "acc_fgsm = test_adversarial(net, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial(net, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial(net, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pretrained VGG19 Accuracy on Clean and Adversarial Examples (CIFAR-100)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8DL2xscsg1Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetV2"
      ],
      "metadata": {
        "id": "aHHr7BXkhTY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare CIFAR-100 data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained MobileNetV2 model and adjust for CIFAR-100\n",
        "print('==> Loading pretrained MobileNetV2 model..')\n",
        "net = models.mobilenet_v2(pretrained=True)\n",
        "net.classifier[1] = nn.Linear(net.last_channel, 100)\n",
        "net = net.to(device)\n",
        "\n",
        "# Fine-tune the model on CIFAR-100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Starting fine-tuning on CIFAR-100..\")\n",
        "for epoch in range(25):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(trainloader):.3f} | Train Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "# Define FGSM and PGD attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "# Carlini-Wagner attack function\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Test function to evaluate model accuracy on clean or adversarial examples\n",
        "def test_adversarial(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    if attack:\n",
        "        print(f'Accuracy on {attack} adversarial examples: {acc:.2f}%')\n",
        "    else:\n",
        "        print(f'Accuracy on clean images: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Evaluate on clean images\n",
        "print(\"==> Evaluating on clean images..\")\n",
        "acc_clean = test_adversarial(net)\n",
        "\n",
        "# Parameters for FGSM, PGD, and C&W attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Testing the pretrained MobileNetV2 model on FGSM, PGD, and C&W attacks\n",
        "acc_fgsm = test_adversarial(net, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial(net, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial(net, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pretrained MobileNetV2 Accuracy on Clean and Adversarial Examples (CIFAR-100)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qPbejFr5g_Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVHN Dataset"
      ],
      "metadata": {
        "id": "9hrIB2WRhqtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet50"
      ],
      "metadata": {
        "id": "LIDPIrpqix41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare SVHN dataset\n",
        "from torchvision.datasets import SVHN\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.198, 0.201, 0.197)),  # SVHN mean and std\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.198, 0.201, 0.197)),  # SVHN mean and std\n",
        "])\n",
        "\n",
        "trainset = SVHN(root='./data', split='train', download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = SVHN(root='./data', split='test', download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained ResNet50 model and adjust for SVHN\n",
        "print('==> Loading pretrained ResNet50 model..')\n",
        "net = models.resnet50(pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 10)  # Adjust final layer for SVHN (10 classes)\n",
        "net = net.to(device)\n",
        "\n",
        "# Fine-tune the model on SVHN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Starting fine-tuning on SVHN..\")\n",
        "for epoch in range(25):  # Adjust number of epochs as needed\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(trainloader):.3f} | Train Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "# Define FGSM and PGD attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "# Carlini-Wagner attack function\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Test function to evaluate model accuracy on clean or adversarial examples\n",
        "def test_adversarial(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    if attack:\n",
        "        print(f'Accuracy on {attack} adversarial examples: {acc:.2f}%')\n",
        "    else:\n",
        "        print(f'Accuracy on clean images: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Evaluate on clean images\n",
        "print(\"==> Evaluating on clean images..\")\n",
        "acc_clean = test_adversarial(net)\n",
        "\n",
        "# Parameters for FGSM, PGD, and C&W attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Testing the pretrained ResNet50 model on FGSM, PGD, and C&W attacks\n",
        "acc_fgsm = test_adversarial(net, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial(net, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial(net, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pretrained ResNet50 Accuracy on Clean and Adversarial Examples (SVHN)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCJuwNuchpoC",
        "outputId": "da3d4644-7d28-44bb-ffc0-34190d0ee0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182M/182M [00:17<00:00, 10.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64.3M/64.3M [00:12<00:00, 5.22MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Loading pretrained ResNet50 model..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Starting fine-tuning on SVHN..\n",
            "Epoch 1: Train Loss: 0.731 | Train Accuracy: 76.45%\n",
            "Epoch 2: Train Loss: 0.209 | Train Accuracy: 93.94%\n",
            "Epoch 3: Train Loss: 0.153 | Train Accuracy: 95.73%\n",
            "Epoch 4: Train Loss: 0.113 | Train Accuracy: 96.95%\n",
            "Epoch 5: Train Loss: 0.083 | Train Accuracy: 97.81%\n",
            "Epoch 6: Train Loss: 0.061 | Train Accuracy: 98.44%\n",
            "Epoch 7: Train Loss: 0.044 | Train Accuracy: 98.80%\n",
            "Epoch 8: Train Loss: 0.033 | Train Accuracy: 99.15%\n",
            "Epoch 9: Train Loss: 0.028 | Train Accuracy: 99.23%\n",
            "Epoch 10: Train Loss: 0.021 | Train Accuracy: 99.39%\n",
            "Epoch 11: Train Loss: 0.019 | Train Accuracy: 99.45%\n",
            "Epoch 12: Train Loss: 0.013 | Train Accuracy: 99.63%\n",
            "Epoch 13: Train Loss: 0.014 | Train Accuracy: 99.59%\n",
            "Epoch 14: Train Loss: 0.009 | Train Accuracy: 99.78%\n",
            "Epoch 15: Train Loss: 0.008 | Train Accuracy: 99.80%\n",
            "Epoch 16: Train Loss: 0.010 | Train Accuracy: 99.71%\n",
            "Epoch 17: Train Loss: 0.009 | Train Accuracy: 99.75%\n",
            "Epoch 18: Train Loss: 0.007 | Train Accuracy: 99.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19"
      ],
      "metadata": {
        "id": "D_Gip3mqjLGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare SVHN dataset\n",
        "from torchvision.datasets import SVHN\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.198, 0.201, 0.197)),  # SVHN mean and std\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.198, 0.201, 0.197)),  # SVHN mean and std\n",
        "])\n",
        "\n",
        "trainset = SVHN(root='./data', split='train', download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = SVHN(root='./data', split='test', download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained VGG19 model and adjust for SVHN\n",
        "print('==> Loading pretrained VGG19 model..')\n",
        "net = models.vgg19(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(4096, 10)  # Adjust final layer for SVHN (10 classes)\n",
        "net = net.to(device)\n",
        "\n",
        "# Fine-tune the model on SVHN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Starting fine-tuning on SVHN..\")\n",
        "for epoch in range(25):  # Adjust number of epochs as needed\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(trainloader):.3f} | Train Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "# Define FGSM and PGD attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "# Carlini-Wagner attack function\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Test function to evaluate model accuracy on clean or adversarial examples\n",
        "def test_adversarial(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    if attack:\n",
        "        print(f'Accuracy on {attack} adversarial examples: {acc:.2f}%')\n",
        "    else:\n",
        "        print(f'Accuracy on clean images: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Evaluate on clean images\n",
        "print(\"==> Evaluating on clean images..\")\n",
        "acc_clean = test_adversarial(net)\n",
        "\n",
        "# Parameters for FGSM, PGD, and C&W attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Testing the pretrained VGG19 model on FGSM, PGD, and C&W attacks\n",
        "acc_fgsm = test_adversarial(net, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial(net, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial(net, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pretrained VGG19 Accuracy on Clean and Adversarial Examples (SVHN)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tWdtliDljJdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobilenetV2"
      ],
      "metadata": {
        "id": "VpB2PptGj64P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare SVHN dataset\n",
        "from torchvision.datasets import SVHN\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.198, 0.201, 0.197)),  # SVHN mean and std\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.198, 0.201, 0.197)),  # SVHN mean and std\n",
        "])\n",
        "\n",
        "trainset = SVHN(root='./data', split='train', download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = SVHN(root='./data', split='test', download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained MobileNetV2 model and adjust for SVHN\n",
        "print('==> Loading pretrained MobileNetV2 model..')\n",
        "net = models.mobilenet_v2(pretrained=True)\n",
        "net.classifier[1] = nn.Linear(net.last_channel, 10)  # Adjust final layer for SVHN (10 classes)\n",
        "net = net.to(device)\n",
        "\n",
        "# Fine-tune the model on SVHN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Starting fine-tuning on SVHN..\")\n",
        "for epoch in range(25):  # Adjust number of epochs as needed\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(trainloader):.3f} | Train Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "# Define FGSM and PGD attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "# Carlini-Wagner attack function\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Test function to evaluate model accuracy on clean or adversarial examples\n",
        "def test_adversarial(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    if attack:\n",
        "        print(f'Accuracy on {attack} adversarial examples: {acc:.2f}%')\n",
        "    else:\n",
        "        print(f'Accuracy on clean images: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Evaluate on clean images\n",
        "print(\"==> Evaluating on clean images..\")\n",
        "acc_clean = test_adversarial(net)\n",
        "\n",
        "# Parameters for FGSM, PGD, and C&W attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Testing the pretrained MobileNetV2 model on FGSM, PGD, and C&W attacks\n",
        "acc_fgsm = test_adversarial(net, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial(net, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial(net, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pretrained MobileNetV2 Accuracy on Clean and Adversarial Examples (SVHN)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gjIKVwBNj6Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Diffensive Distilations"
      ],
      "metadata": {
        "id": "XP45RKSNhxNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5qFDIRreUuoq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare CIFAR-100 data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained ResNet50 model and adjust for CIFAR-100\n",
        "print('==> Loading pretrained ResNet50 model..')\n",
        "teacher_model = models.resnet50(pretrained=True)\n",
        "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, 100)  # Adjust final layer for CIFAR-100\n",
        "teacher_model = teacher_model.to(device)\n",
        "\n",
        "# Train the teacher model (pretrained ResNet50)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(teacher_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Fine-tuning the teacher model..\")\n",
        "for epoch in range(5):  # Adjust epochs as needed\n",
        "    teacher_model.train()\n",
        "    for inputs, targets in trainloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Generate soft labels with temperature\n",
        "def generate_soft_labels(model, dataloader, temperature=10):\n",
        "    soft_labels = []\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs) / temperature\n",
        "            soft_labels.append((inputs, torch.softmax(outputs, dim=1)))\n",
        "    return soft_labels\n",
        "\n",
        "soft_train_labels = generate_soft_labels(teacher_model, trainloader)\n",
        "\n",
        "# Train the distilled (student) model\n",
        "student_model = models.resnet50(pretrained=True)\n",
        "student_model.fc = nn.Linear(student_model.fc.in_features, 100)  # Adjust final layer for CIFAR-100\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(student_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "def train_student(model, soft_labels, temperature=10):\n",
        "    model.train()\n",
        "    for epoch in range(5):\n",
        "        total_loss = 0\n",
        "        for inputs, soft_targets in soft_labels:\n",
        "            inputs, soft_targets = inputs.to(device), soft_targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs) / temperature\n",
        "            loss = nn.KLDivLoss()(torch.log_softmax(outputs, dim=1), soft_targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}: Loss: {total_loss/len(soft_labels):.3f}\")\n",
        "\n",
        "print(\"==> Training the student model with defensive distillation..\")\n",
        "train_student(student_model, soft_train_labels)\n",
        "\n",
        "# Evaluate the student model under adversarial attacks\n",
        "def test_adversarial_defense(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print(f'Accuracy on {attack if attack else \"clean\"} examples: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# FGSM, PGD, and CW attack functions remain the same as before\n",
        "# Parameters for FGSM, PGD, and CW attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Test the student model\n",
        "print(\"==> Evaluating the student model under adversarial attacks..\")\n",
        "acc_clean = test_adversarial_defense(student_model)\n",
        "acc_fgsm = test_adversarial_defense(student_model, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial_defense(student_model, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial_defense(student_model, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Defensive Distillation with ResNet50 (CIFAR-100)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19"
      ],
      "metadata": {
        "id": "WokWjXy_k572"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare CIFAR-100 data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained VGG19 model and adjust for CIFAR-100\n",
        "print('==> Loading pretrained VGG19 model as the teacher model..')\n",
        "teacher_model = models.vgg19(pretrained=True)\n",
        "teacher_model.classifier[6] = nn.Linear(4096, 100)  # Adjust the final layer for CIFAR-100\n",
        "teacher_model = teacher_model.to(device)\n",
        "\n",
        "# Train the teacher model (pretrained VGG19)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(teacher_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Fine-tuning the teacher model..\")\n",
        "for epoch in range(5):  # Adjust epochs as needed\n",
        "    teacher_model.train()\n",
        "    for inputs, targets in trainloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Generate soft labels with temperature\n",
        "def generate_soft_labels(model, dataloader, temperature=10):\n",
        "    soft_labels = []\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs) / temperature\n",
        "            soft_labels.append((inputs, torch.softmax(outputs, dim=1)))\n",
        "    return soft_labels\n",
        "\n",
        "soft_train_labels = generate_soft_labels(teacher_model, trainloader)\n",
        "\n",
        "# Train the distilled (student) model\n",
        "student_model = models.vgg19(pretrained=True)\n",
        "student_model.classifier[6] = nn.Linear(4096, 100)  # Adjust the final layer for CIFAR-100\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(student_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "def train_student(model, soft_labels, temperature=10):\n",
        "    model.train()\n",
        "    for epoch in range(5):\n",
        "        total_loss = 0\n",
        "        for inputs, soft_targets in soft_labels:\n",
        "            inputs, soft_targets = inputs.to(device), soft_targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs) / temperature\n",
        "            loss = nn.KLDivLoss()(torch.log_softmax(outputs, dim=1), soft_targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}: Loss: {total_loss/len(soft_labels):.3f}\")\n",
        "\n",
        "print(\"==> Training the student model with defensive distillation..\")\n",
        "train_student(student_model, soft_train_labels)\n",
        "\n",
        "# FGSM, PGD, and CW attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Evaluate the student model under adversarial attacks\n",
        "def test_adversarial_defense(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print(f'Accuracy on {attack if attack else \"clean\"} examples: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Parameters for FGSM, PGD, and CW attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Test the student model\n",
        "print(\"==> Evaluating the student model under adversarial attacks..\")\n",
        "acc_clean = test_adversarial_defense(student_model)\n",
        "acc_fgsm = test_adversarial_defense(student_model, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial_defense(student_model, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial_defense(student_model, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Defensive Distillation with VGG19 (CIFAR-100)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2utGT58ik7IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetv2"
      ],
      "metadata": {
        "id": "8bfIowwLlTPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Prepare CIFAR-100 data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Rescale to 224x224 to match ImageNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained MobileNetV2 model and adjust for CIFAR-100\n",
        "print('==> Loading pretrained MobileNetV2 model as the teacher model..')\n",
        "teacher_model = models.mobilenet_v2(pretrained=True)\n",
        "teacher_model.classifier[1] = nn.Linear(teacher_model.last_channel, 100)  # Adjust the final layer for CIFAR-100\n",
        "teacher_model = teacher_model.to(device)\n",
        "\n",
        "# Train the teacher model (pretrained MobileNetV2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(teacher_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "print(\"==> Fine-tuning the teacher model..\")\n",
        "for epoch in range(5):  # Adjust epochs as needed\n",
        "    teacher_model.train()\n",
        "    for inputs, targets in trainloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Generate soft labels with temperature\n",
        "def generate_soft_labels(model, dataloader, temperature=10):\n",
        "    soft_labels = []\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs) / temperature\n",
        "            soft_labels.append((inputs, torch.softmax(outputs, dim=1)))\n",
        "    return soft_labels\n",
        "\n",
        "soft_train_labels = generate_soft_labels(teacher_model, trainloader)\n",
        "\n",
        "# Train the distilled (student) model\n",
        "student_model = models.mobilenet_v2(pretrained=True)\n",
        "student_model.classifier[1] = nn.Linear(student_model.last_channel, 100)  # Adjust the final layer for CIFAR-100\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(student_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "def train_student(model, soft_labels, temperature=10):\n",
        "    model.train()\n",
        "    for epoch in range(5):\n",
        "        total_loss = 0\n",
        "        for inputs, soft_targets in soft_labels:\n",
        "            inputs, soft_targets = inputs.to(device), soft_targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs) / temperature\n",
        "            loss = nn.KLDivLoss()(torch.log_softmax(outputs, dim=1), soft_targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}: Loss: {total_loss/len(soft_labels):.3f}\")\n",
        "\n",
        "print(\"==> Training the student model with defensive distillation..\")\n",
        "train_student(student_model, soft_train_labels)\n",
        "\n",
        "# FGSM, PGD, and CW attack functions\n",
        "def fgsm_attack(model, x, y, epsilon):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    output = model(x_adv)\n",
        "    loss = criterion(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv\n",
        "\n",
        "def pgd_attack(model, x, y, alpha, epsilon, num_iter):\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
        "    for _ in range(num_iter):\n",
        "        output = model(x_adv)\n",
        "        loss = criterion(output, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "        eta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
        "        x_adv = torch.clamp(x + eta, 0, 1).detach_().requires_grad_(True)\n",
        "    return x_adv\n",
        "\n",
        "def carlini_wagner_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, num_iter=100, learning_rate=0.01):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.to(device)\n",
        "    adv_images = images.clone().detach()\n",
        "    adv_images.requires_grad = True\n",
        "    optimizer = optim.Adam([adv_images], lr=learning_rate)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(adv_images)\n",
        "\n",
        "        if targeted:\n",
        "            target_class = labels\n",
        "            f_loss = torch.max((outputs - outputs.gather(1, target_class.view(-1, 1)).squeeze() + kappa).clamp(min=0))\n",
        "        else:\n",
        "            correct_class = outputs.gather(1, labels.view(-1, 1)).squeeze()\n",
        "            f_loss = torch.max((correct_class - outputs + kappa).clamp(min=0), 1).values.mean()\n",
        "\n",
        "        l2_loss = torch.norm((adv_images - images).view(images.size(0), -1), dim=1).mean()\n",
        "        loss = l2_loss + c * f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        adv_images.data = torch.clamp(adv_images.data, 0, 1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "# Evaluate the student model under adversarial attacks\n",
        "def test_adversarial_defense(model, attack=None, epsilon=None, alpha=None, num_iter=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    for inputs, targets in testloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            inputs = fgsm_attack(model, inputs, targets, epsilon)\n",
        "        elif attack == 'PGD':\n",
        "            inputs = pgd_attack(model, inputs, targets, alpha, epsilon, num_iter)\n",
        "        elif attack == 'CW':\n",
        "            inputs = carlini_wagner_attack(model, inputs, targets, targeted=False, num_iter=100, learning_rate=0.01)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print(f'Accuracy on {attack if attack else \"clean\"} examples: {acc:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Parameters for FGSM, PGD, and CW attacks\n",
        "epsilon_fgsm = 0.1\n",
        "epsilon_pgd = 2 / 255\n",
        "alpha = 2 / 255\n",
        "num_iter = 5\n",
        "\n",
        "# Test the student model\n",
        "print(\"==> Evaluating the student model under adversarial attacks..\")\n",
        "acc_clean = test_adversarial_defense(student_model)\n",
        "acc_fgsm = test_adversarial_defense(student_model, attack='FGSM', epsilon=epsilon_fgsm)\n",
        "acc_pgd = test_adversarial_defense(student_model, attack='PGD', epsilon=epsilon_pgd, alpha=alpha, num_iter=num_iter)\n",
        "acc_cw = test_adversarial_defense(student_model, attack='CW')\n",
        "\n",
        "# Plot results\n",
        "attacks = ['Clean', 'FGSM', 'PGD', 'C&W']\n",
        "accuracies = [acc_clean, acc_fgsm, acc_pgd, acc_cw]\n",
        "plt.bar(attacks, accuracies)\n",
        "plt.xlabel('Attack')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Defensive Distillation with MobileNetV2 (CIFAR-100)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "umdBO9H9lQdA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}